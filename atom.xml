<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LeeZePeng&#39;s Blog</title>
  
  <subtitle>知行合一，经世致用</subtitle>
  <link href="https://leezepeng.github.io/atom.xml" rel="self"/>
  
  <link href="https://leezepeng.github.io/"/>
  <updated>2021-03-16T13:56:30.844Z</updated>
  <id>https://leezepeng.github.io/</id>
  
  <author>
    <name>LeeZePeng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>JAVA复习-基础部分</title>
    <link href="https://leezepeng.github.io/2021/03/16/JAVA%E5%A4%8D%E4%B9%A0-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"/>
    <id>https://leezepeng.github.io/2021/03/16/JAVA%E5%A4%8D%E4%B9%A0-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/</id>
    <published>2021-03-16T11:30:11.000Z</published>
    <updated>2021-03-16T13:56:30.844Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JAVA入门重点"><a href="#JAVA入门重点" class="headerlink" title="JAVA入门重点"></a>JAVA入门重点</h2><h3 id="关于-JVM-JDK-和-JRE"><a href="#关于-JVM-JDK-和-JRE" class="headerlink" title="关于 JVM JDK 和 JRE"></a>关于 JVM JDK 和 JRE</h3><h4 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h4><p>程序从源代码到运行一般有下面 3 步：</p><p><img src="JAVA复习-基础部分/Java 程序运行过程.png" alt="Java程序运行过程"></p><p>我们需要格外注意的是 .class-&gt;机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。</p><span id="more"></span><p><strong>总结：Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。</strong></p><h4 id="jdk和jre"><a href="#jdk和jre" class="headerlink" title="jdk和jre"></a>jdk和jre</h4><ul><li>JDK 是 Java Development Kit 缩写，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。</li><li>JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。</li><li>有时不打算在计算机上进行任何 Java 开发，仍然需要安装 JDK。例如，要使用 JSP 部署 Web 应用程序，应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。</li></ul><h4 id="Oracle-JDK-和-OpenJDK-的对比"><a href="#Oracle-JDK-和-OpenJDK-的对比" class="headerlink" title="Oracle JDK 和 OpenJDK 的对比"></a>Oracle JDK 和 OpenJDK 的对比</h4><ol><li>Oracle JDK 大概每 6 个月发一次主要版本，而 OpenJDK 版本大概每三个月发布一次。但这不是固定的，我觉得了解这个没啥用处。详情参见：<a href="https://blogs.oracle.com/java-platform-group/update-and-faq-on-the-java-se-release-cadence">https://blogs.oracle.com/java-platform-group/update-and-faq-on-the-java-se-release-cadence</a> 。</li><li>OpenJDK 是一个参考模型并且是完全开源的，而 Oracle JDK 是 OpenJDK 的一个实现，并不是完全开源的；</li><li>Oracle JDK 比 OpenJDK 更稳定。OpenJDK 和 Oracle JDK 的代码几乎相同，但 Oracle JDK 有更多的类和一些错误修复。因此，如果您想开发企业/商业软件，我建议您选择 Oracle JDK，因为它经过了彻底的测试和稳定。某些情况下，有些人提到在使用 OpenJDK 可能会遇到了许多应用程序崩溃的问题，但是，只需切换到 Oracle JDK 就可以解决问题；</li><li>在响应性和 JVM 性能方面，Oracle JDK 与 OpenJDK 相比提供了更好的性能；</li><li>Oracle JDK 不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本；</li><li>Oracle JDK 根据二进制代码许可协议获得许可，而 OpenJDK 根据 GPL v2 许可获得许可。</li></ol><h3 id="Java-和-C-的区别"><a href="#Java-和-C-的区别" class="headerlink" title="Java 和 C++的区别"></a>Java 和 C++的区别</h3><ul><li>都是面向对象的语言，都支持封装、继承和多态</li><li>Java 不提供指针来直接访问内存，程序内存更加安全</li><li>Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。</li><li>Java 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存</li><li><strong>在 C 语言中，字符串或字符数组最后都会有一个额外的字符<code>&#39;\0&#39;</code>来表示结束。但是，Java 语言中没有结束符这一概念。</strong> 这是一个值得深度思考的问题，具体原因推荐看这篇文章： <a href="https://blog.csdn.net/sszgg2006/article/details/49148189">https://blog.csdn.net/sszgg2006/article/details/49148189</a></li></ul><h3 id="Java-泛型了解么？什么是类型擦除？介绍一下常用的通配符？"><a href="#Java-泛型了解么？什么是类型擦除？介绍一下常用的通配符？" class="headerlink" title="Java 泛型了解么？什么是类型擦除？介绍一下常用的通配符？"></a>Java 泛型了解么？什么是类型擦除？介绍一下常用的通配符？</h3><blockquote><p><strong>Java 泛型（generics）</strong>是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。</p></blockquote><p><strong>Java 的泛型是伪泛型，这是因为 Java 在编译期间，所有的泛型信息都会被擦掉。</strong></p><p>举个🌰：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        ArrayList&lt;String&gt; list1 = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">        list1.add(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line"></span><br><span class="line">        ArrayList&lt;Integer&gt; list2 = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">        list2.add(<span class="number">123</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(list1.getClass() == list2.getClass());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们定义了两个<code>ArrayList</code>数组，不过一个是<code>ArrayList&lt;String&gt;</code>泛型类型的，只能存储字符串；一个是<code>ArrayList&lt;Integer&gt;</code>泛型类型的，只能存储整数，最后，我们通过<code>list1</code>对象和<code>list2</code>对象的<code>getClass()</code>方法获取他们的类的信息，最后发现结果为<code>true</code>。说明泛型类型<code>String</code>和<code>Integer</code>都被擦除掉了，只剩下原始类型。</p><blockquote><p>关于类型擦出引起的问题以及jvm的解决方法将在下一篇博客介绍</p></blockquote><p><strong>常用的通配符为： T，E，K，V，？</strong></p><ul><li>？ 表示不确定的 java 类型</li><li>T (type) 表示具体的一个 java 类型</li><li>K V (key value) 分别代表 java 键值中的 Key Value</li><li>E (element) 代表 Element</li></ul><h3 id="和-equals-的区别"><a href="#和-equals-的区别" class="headerlink" title="==和 equals 的区别"></a>==和 equals 的区别</h3><p><strong>Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。</strong></p><ul><li>当类没有覆盖 <code>equals()</code>方法。则通过<code>equals()</code>比较该类的两个对象时，等价于通过“==”比较这两个对象。使用的默认是 <code>Object</code>类<code>equals()</code>方法。</li><li>当类覆盖了 <code>equals()</code>方法。一般，我们都覆盖 <code>equals()</code>方法来两个对象的内容相等；若它们的内容相等，则返回 true(即，认为这两个对象相等)。</li></ul><p>说白了就是<code>equals()</code>最开始是<code>object</code>自带的，用于比较两个对象是否是同一个对象，但是如果你自己<code>@overide</code>或者本身就被<code>@overide</code>了，<code>equals()</code>的方法当然是自己定义的啦～</p><p><strong>说明：</strong></p><ul><li><code>String</code> 中的 <code>equals</code> 方法是被重写过的，因为 <code>Object</code> 的 <code>equals</code> 方法是比较的对象的内存地址，而 <code>String</code> 的 <code>equals</code>方法比较的是对象的值。</li><li>当创建 <code>String</code> 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 <code>String</code> 对象。</li></ul><p>举个🌰：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">test1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String a = <span class="keyword">new</span> String(<span class="string">&quot;ab&quot;</span>); <span class="comment">// a 为一个引用</span></span><br><span class="line">        String b = <span class="keyword">new</span> String(<span class="string">&quot;ab&quot;</span>); <span class="comment">// b为另一个引用,对象的内容一样</span></span><br><span class="line">        String aa = <span class="string">&quot;ab&quot;</span>; <span class="comment">// 放在常量池中</span></span><br><span class="line">        String bb = <span class="string">&quot;ab&quot;</span>; <span class="comment">// 从常量池中查找</span></span><br><span class="line">        <span class="keyword">if</span> (aa == bb) <span class="comment">// true</span></span><br><span class="line">            System.out.println(<span class="string">&quot;aa==bb&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (a == b) <span class="comment">// false，非同一对象</span></span><br><span class="line">            System.out.println(<span class="string">&quot;a==b&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (a.equals(b)) <span class="comment">// true</span></span><br><span class="line">            System.out.println(<span class="string">&quot;aEQb&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">42</span> == <span class="number">42.0</span>) &#123; <span class="comment">// true</span></span><br><span class="line">            System.out.println(<span class="string">&quot;true&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h4><p><strong>Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character 创建了数值在[0,127]范围的缓存数据，Boolean 直接返回 True Or False。如果超出对应范围仍然会去创建新的对象。两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。</strong></p><p><img src="JAVA复习-基础部分/SouthEast.png" alt="这里写图片描述"></p><p><code>String s1 = new String(&quot;hello&quot;)</code>创建了两个对象，首先<code>new</code>了一个堆空间，这个堆空间会在字符串常量池中创建“hello”字符串，然后字符串地址赋值给堆，堆地址赋值给s1。而s2直接指向字符串常量池。<a href="https://www.cnblogs.com/taochen-go/p/9475947.html">参考地址</a></p><h4 id="hashCode-与-equals-重要"><a href="#hashCode-与-equals-重要" class="headerlink" title="hashCode 与 equals (重要)"></a>hashCode 与 equals (重要)</h4><blockquote><p>hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在 JDK 的 Object.java 中，这就意味着 Java 中的任何类都包含有 hashCode() 函数。</p><p>散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）</p></blockquote><ol><li><h5 id="为什么要有-hashCode"><a href="#为什么要有-hashCode" class="headerlink" title="为什么要有 hashCode"></a>为什么要有 hashCode</h5><p><strong>我们先以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode：</strong> 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与该位置其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 <code>equals()</code>方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。<em>（摘自我的 Java 启蒙书《Head first java》第二版）</em>。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。</p></li><li><h5 id="hashCode-与-equals-的相关规定"><a href="#hashCode-与-equals-的相关规定" class="headerlink" title="hashCode()与 equals()的相关规定"></a>hashCode()与 equals()的相关规定</h5><ul><li>如果两个对象相等，则 hashcode 一定也是相同的</li><li>两个对象相等,对两个对象分别调用 equals 方法都返回 true</li><li>两个对象有相同的 hashcode 值，它们也不一定是相等的</li><li><strong>因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖</strong></li><li>hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）</li></ul></li><li><p><strong>equals 方法被覆盖过，则 hashCode 方法也必须被覆盖</strong></p><p>两个很好的🌰：<a href="https://www.cnblogs.com/skywang12345/p/3324958.html">参考地址</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> java.lang.Comparable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@desc</span> 比较equals() 返回true 以及 返回false时， hashCode()的值。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> skywang</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@emai</span> kuiwu-wang@163.com</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConflictHashCodeTest1</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 新建Person对象，</span></span><br><span class="line">        Person p1 = <span class="keyword">new</span> Person(<span class="string">&quot;eee&quot;</span>, <span class="number">100</span>);</span><br><span class="line">        Person p2 = <span class="keyword">new</span> Person(<span class="string">&quot;eee&quot;</span>, <span class="number">100</span>);</span><br><span class="line">        Person p3 = <span class="keyword">new</span> Person(<span class="string">&quot;aaa&quot;</span>, <span class="number">200</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 新建HashSet对象</span></span><br><span class="line">        HashSet set = <span class="keyword">new</span> HashSet();</span><br><span class="line">        set.add(p1);</span><br><span class="line">        set.add(p2);</span><br><span class="line">        set.add(p3);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 比较p1 和 p2， 并打印它们的hashCode()</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\n&quot;</span>, p1.equals(p2), p1.hashCode(), p2.hashCode());<span class="comment">//p1.equals(p2) : true; p1(1169863946) p2(1690552137)</span></span><br><span class="line">        <span class="comment">// 打印set</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;set:%s\n&quot;</span>, set);<span class="comment">//set:[(eee, 100), (eee, 100), (aaa, 200)]   (eee,100)未被合并</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@desc</span> Person类。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> age;</span><br><span class="line">        String name;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">            <span class="keyword">this</span>.age = age;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;(&quot;</span>+name + <span class="string">&quot;, &quot;</span> +age+<span class="string">&quot;)&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@desc</span> 覆盖equals方法</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span></span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(obj == <span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//如果是同一个对象返回true，反之返回false</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span> == obj)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//判断是否类型相同</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span>.getClass() != obj.getClass())&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            Person person = (Person)obj;</span><br><span class="line">            <span class="keyword">return</span> name.equals(person.name) &amp;&amp; age==person.age;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> java.lang.Comparable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@desc</span> 比较equals() 返回true 以及 返回false时， hashCode()的值。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> skywang</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@emai</span> kuiwu-wang@163.com</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConflictHashCodeTest2</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 新建Person对象，</span></span><br><span class="line">        Person p1 = <span class="keyword">new</span> Person(<span class="string">&quot;eee&quot;</span>, <span class="number">100</span>);</span><br><span class="line">        Person p2 = <span class="keyword">new</span> Person(<span class="string">&quot;eee&quot;</span>, <span class="number">100</span>);</span><br><span class="line">        Person p3 = <span class="keyword">new</span> Person(<span class="string">&quot;aaa&quot;</span>, <span class="number">200</span>);</span><br><span class="line">        Person p4 = <span class="keyword">new</span> Person(<span class="string">&quot;EEE&quot;</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 新建HashSet对象</span></span><br><span class="line">        HashSet set = <span class="keyword">new</span> HashSet();</span><br><span class="line">        set.add(p1);</span><br><span class="line">        set.add(p2);</span><br><span class="line">        set.add(p3);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 比较p1 和 p2， 并打印它们的hashCode()</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\n&quot;</span>, p1.equals(p2), p1.hashCode(), p2.hashCode());<span class="comment">//p1.equals(p2) : true; p1(68545) p2(68545)</span></span><br><span class="line">        <span class="comment">// 比较p1 和 p4， 并打印它们的hashCode()</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;p1.equals(p4) : %s; p1(%d) p4(%d)\n&quot;</span>, p1.equals(p4), p1.hashCode(), p4.hashCode());<span class="comment">//p1.equals(p4) : false; p1(68545) p4(68545)</span></span><br><span class="line">        <span class="comment">// 打印set</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;set:%s\n&quot;</span>, set);<span class="comment">//set:[aaa - 200, eee - 100]</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@desc</span> Person类。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> age;</span><br><span class="line">        String name;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">            <span class="keyword">this</span>.age = age;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name + <span class="string">&quot; - &quot;</span> +age;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@desc</span>重写hashCode</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> nameHash =  name.toUpperCase().hashCode();</span><br><span class="line">            <span class="keyword">return</span> nameHash ^ age;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@desc</span> 覆盖equals方法</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span></span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(obj == <span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//如果是同一个对象返回true，反之返回false</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span> == obj)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//判断是否类型相同</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span>.getClass() != obj.getClass())&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            Person person = (Person)obj;</span><br><span class="line">            <span class="keyword">return</span> name.equals(person.name) &amp;&amp; age==person.age;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><h4 id="Java-中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？"><a href="#Java-中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？" class="headerlink" title="Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？"></a>Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？</h4><p>Java<strong>中</strong>有 8 种基本数据类型，分别为：</p><ol><li>6 种数字类型 ：byte、short、int、long、float、double</li><li>1 种字符类型：char</li><li>1 种布尔型：boolean。</li></ol><p>这八种基本类型都有对应的包装类分别为：Byte、Short、Integer、Long、Float、Double、Character、Boolean</p><div class="table-container"><table><thead><tr><th>基本类型</th><th>位数</th><th>字节</th><th>默认值</th></tr></thead><tbody><tr><td>int</td><td>32</td><td>4</td><td>0</td></tr><tr><td>short</td><td>16</td><td>2</td><td>0</td></tr><tr><td>long</td><td>64</td><td>8</td><td>0L</td></tr><tr><td>byte</td><td>8</td><td>1</td><td>0</td></tr><tr><td>char</td><td>16</td><td>2</td><td>‘u0000’</td></tr><tr><td>float</td><td>32</td><td>4</td><td>0f</td></tr><tr><td>double</td><td>64</td><td>8</td><td>0d</td></tr><tr><td>boolean</td><td>1</td><td></td><td>false</td></tr></tbody></table></div><h4 id="自动装箱与拆箱"><a href="#自动装箱与拆箱" class="headerlink" title="自动装箱与拆箱"></a>自动装箱与拆箱</h4><blockquote><p><strong>当 “==”运算符的两个操作数都是 包装器类型的引用，则是比较指向的是否是同一个对象，而如果其中有一个操作数是表达式（即包含算术运算）则比较的是数值（即会触发自动拆箱的过程）。</strong></p></blockquote><p>举个🌰：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Integer a = <span class="number">1</span>;</span><br><span class="line">        Integer b = <span class="number">2</span>;</span><br><span class="line">        Integer c = <span class="number">3</span>;</span><br><span class="line">        Integer d = <span class="number">3</span>;</span><br><span class="line">        Integer e = <span class="number">321</span>;</span><br><span class="line">        Integer f = <span class="number">321</span>;</span><br><span class="line">        Long g = <span class="number">3L</span>;</span><br><span class="line">        Long h = <span class="number">2L</span>;</span><br><span class="line"></span><br><span class="line">        System.out.println(c==d);<span class="comment">//true</span></span><br><span class="line">        System.out.println(e==f);<span class="comment">//false</span></span><br><span class="line">        System.out.println(c==(a+b));<span class="comment">//true 第三句由于a+b包含了算术运算，因此会触发自动拆箱过程（会调用intValue方法），因此它们比较的是数值是否相等。</span></span><br><span class="line">        System.out.println(c.equals(a+b));<span class="comment">//true</span></span><br><span class="line">        System.out.println(g==(a+b));<span class="comment">//true</span></span><br><span class="line">        System.out.println(g.equals(a+b));<span class="comment">//false</span></span><br><span class="line">        System.out.println(g.equals(a+h));<span class="comment">//true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;JAVA入门重点&quot;&gt;&lt;a href=&quot;#JAVA入门重点&quot; class=&quot;headerlink&quot; title=&quot;JAVA入门重点&quot;&gt;&lt;/a&gt;JAVA入门重点&lt;/h2&gt;&lt;h3 id=&quot;关于-JVM-JDK-和-JRE&quot;&gt;&lt;a href=&quot;#关于-JVM-JDK-和-JRE&quot; class=&quot;headerlink&quot; title=&quot;关于 JVM JDK 和 JRE&quot;&gt;&lt;/a&gt;关于 JVM JDK 和 JRE&lt;/h3&gt;&lt;h4 id=&quot;jvm&quot;&gt;&lt;a href=&quot;#jvm&quot; class=&quot;headerlink&quot; title=&quot;jvm&quot;&gt;&lt;/a&gt;jvm&lt;/h4&gt;&lt;p&gt;程序从源代码到运行一般有下面 3 步：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;JAVA复习-基础部分/Java 程序运行过程.png&quot; alt=&quot;Java程序运行过程&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们需要格外注意的是 .class-&amp;gt;机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。&lt;/p&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://leezepeng.github.io/categories/JAVA/"/>
    
    
    <category term="JAVA知识" scheme="https://leezepeng.github.io/tags/JAVA%E7%9F%A5%E8%AF%86/"/>
    
    <category term="笔记" scheme="https://leezepeng.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>刷题记录-剑指offer(一)</title>
    <link href="https://leezepeng.github.io/2021/03/15/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95-%E5%89%91%E6%8C%87offer-%E4%B8%80/"/>
    <id>https://leezepeng.github.io/2021/03/15/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95-%E5%89%91%E6%8C%87offer-%E4%B8%80/</id>
    <published>2021-03-15T09:41:11.000Z</published>
    <updated>2021-03-15T09:43:14.066Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、数组中重复的数字"><a href="#1、数组中重复的数字" class="headerlink" title="1、数组中重复的数字"></a>1、数组中重复的数字</h2><p>找出数组中重复的数字。</p><p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p><p>示例 1：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：</span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line">输出：<span class="number">2</span> 或 <span class="number">3</span> </span><br></pre></td></tr></table></figure><p>限制：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span> &lt;= n &lt;= <span class="number">100000</span></span><br></pre></td></tr></table></figure><span id="more"></span><blockquote><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof">https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p></blockquote><h3 id="题目分析："><a href="#题目分析：" class="headerlink" title="题目分析："></a>题目分析：</h3><p>我们需要从题目中挖掘定量的隐含条件，<u>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内</u>，如果没有数字重复，那么一定是0～n-1所有的数都存在。可以选择用排序的方法，如果没有数字重复，那么必然有<code>nums[i] == i</code>，扫描一边排序后的数组，如果<code>nums[i] != i</code>那么<code>nums[i]</code>一定是重复的。但是排序需要消耗的时间至少是$O(nlog(n))$，我们也没必要进行完全排序，排序也就是相当于元素归位，当两个元素会被归到相同的位置时，该元素一定是重复的。</p><h3 id="原地置换图解（来源——leetcode吃拌面想喝汤）"><a href="#原地置换图解（来源——leetcode吃拌面想喝汤）" class="headerlink" title="原地置换图解（来源——leetcode吃拌面想喝汤）"></a>原地置换图解（来源——leetcode<a href="https://leetcode-cn.com/u/chi-ban-mian-xiang-he-tang/">吃拌面想喝汤</a>）</h3><p>这种原地置换的想法确实挺精妙的。</p><p>1、题目明确说明了数组长度为n，范围为 n-1，也就是若无重复元素排序后下标0123对应的数字就应该是0123；</p><p>2、对数组排序，其实也就是让萝卜归位，1号坑要放1号萝卜，2号坑要放2号萝卜……排序过程中查找有无重复元素。先考虑没有重复元素的情况：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">3</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">2</span>   <span class="string">萝卜</span>   </span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>   <span class="string">坑</span>  </span><br></pre></td></tr></table></figure><p>0号坑说我要的是0号萝卜，不要3号萝卜，所以会去和3号坑的萝卜交换，因为如果0号坑拿了3号坑的3号萝卜，那说明3号坑装的也肯定是别人家的萝卜，所以要跟3号坑换，换完是这样的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">2</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">3</span>   <span class="string">萝卜</span>  </span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>   <span class="string">坑</span> </span><br></pre></td></tr></table></figure><p>然而0号坑还没找到自己的萝卜，它不要2号萝卜，又去和2号坑的萝卜交换，换完是这样的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>   <span class="string">萝卜</span> </span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>   <span class="string">坑</span>  </span><br></pre></td></tr></table></figure><p>这时候刚好就是一一对应的，交换过程也不会出现不同坑有相同编号的萝卜。要注意交换用的是while，也就是0号坑只有拿到0号萝卜，1号坑才能开始找自己的萝卜。</p><p>3、如果有重复元素，例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">2</span>    <span class="string">萝卜</span></span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>    <span class="string">坑</span></span><br></pre></td></tr></table></figure><p>同样的，0号坑不要1号，先和1号坑交换，交换完这样的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">2</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">2</span>    <span class="string">萝卜</span></span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>    <span class="string">坑</span></span><br></pre></td></tr></table></figure><p>0号坑不要2号萝卜，去和2号坑交换，交换完这样的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">3</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">2</span>    <span class="string">萝卜</span></span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>    <span class="string">坑</span></span><br></pre></td></tr></table></figure><p>0号坑不要3号萝卜，去和3号坑交换，交换完这样的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nums[i]</span>     <span class="number">2</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>    <span class="string">萝卜</span></span><br><span class="line">    <span class="string">i</span>       <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>    <span class="string">坑</span></span><br></pre></td></tr></table></figure><p>0号坑不要2号萝卜，去和2号坑交换，结果发现你2号坑也是2号萝卜，那我还换个锤子，同时也说明有重复元素出现。</p><p>4、总结</p><p>其实这种原地交换就是为了降低空间复杂度，只需多要1个坑来周转交换的萝卜就好了，空间复杂度O（1）。</p><h3 id="JAVA代码"><a href="#JAVA代码" class="headerlink" title="JAVA代码"></a>JAVA代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findRepeatNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> temp = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums.length ; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(nums[i] != i)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] == nums[nums[i]])&#123;</span><br><span class="line">                    <span class="keyword">return</span> nums[i];</span><br><span class="line">                &#125;</span><br><span class="line">                temp = nums[i];</span><br><span class="line">                nums[i] = nums[temp];</span><br><span class="line">                nums[temp] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1、数组中重复的数字&quot;&gt;&lt;a href=&quot;#1、数组中重复的数字&quot; class=&quot;headerlink&quot; title=&quot;1、数组中重复的数字&quot;&gt;&lt;/a&gt;1、数组中重复的数字&lt;/h2&gt;&lt;p&gt;找出数组中重复的数字。&lt;/p&gt;
&lt;p&gt;在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。&lt;/p&gt;
&lt;p&gt;示例 1：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;输入：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输出：&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; 或 &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;限制：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; &amp;lt;= n &amp;lt;= &lt;span class=&quot;number&quot;&gt;100000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="刷题记录" scheme="https://leezepeng.github.io/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="刷题记录" scheme="https://leezepeng.github.io/tags/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    
    <category term="剑指offer" scheme="https://leezepeng.github.io/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>DCRNN_Pytorch代码解析</title>
    <link href="https://leezepeng.github.io/2021/03/13/DCRNN-Pytorch%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>https://leezepeng.github.io/2021/03/13/DCRNN-Pytorch%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</id>
    <published>2021-03-13T12:22:21.000Z</published>
    <updated>2021-03-14T12:53:40.624Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总体框架"><a href="#总体框架" class="headerlink" title="总体框架"></a>总体框架</h2><ol><li>data存放模型用到的数据。其中METR-LA和PEMS-BAY文件夹存放的是scripts中generate_training_data.py生成的数据，model保存的是训练好的模型及其设置参数，sensor_graph保存的是传感器的数据，其中graph_sensor_ids.txt保存了所有数据中所使用的传感器的id，distances_la_2012.csv以csv格式保存了传感器之间的距离。metr-la.h5和pems-bay.h5是两个城市的交通数据。</li><li>figures文件存放的是模型总体结构的图片。</li><li>lib文件包含模型用到的工具函数、优化算法和评价指标。</li><li>model文件中dcrnn_supervisor.py是训练过程中控制整个训练流程的文件，dcrnn_model.py定义了dcrnn模型，dcrnn_cell.py定义了模型中的cell单元，其中实现了核心的扩散卷积。</li><li>scripts包含数据预处理代码，其中gen_adj_mx.py用于生成图的邻接矩阵，generate_training_data.py用于生成训练、验证和测试数据。</li><li>dcrnn_train_pytorch.py是用来训练模型的，run_demo_pytorch.py是用来跑一下已经训练好的模型。</li></ol><span id="more"></span><p><img src="./图片 1.png" style="zoom:60%;" /></p><h2 id="运行说明"><a href="#运行说明" class="headerlink" title="运行说明"></a>运行说明</h2><h3 id="需要安装的依赖"><a href="#需要安装的依赖" class="headerlink" title="需要安装的依赖"></a>需要安装的依赖</h3><ul><li>torch</li><li>scipy&gt;=0.19.0</li><li>numpy&gt;=1.12.1</li><li>pandas&gt;=0.19.2</li><li>pyyaml</li><li>statsmodels</li><li>tensorflow&gt;=1.3.0</li><li>tables</li><li>future</li></ul><p>依赖可以依照下面的命令直接安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p><strong>使用pip安装的一些建议</strong></p><ul><li>得保证pip对应的环境不是base环境，不然会和其他环境冲突，一定要用which python或者where python检查一下是否是自己conda环境内的python。</li><li>最好是使用conda一个个安装</li></ul><h3 id="与tensorflow的效率比较"><a href="#与tensorflow的效率比较" class="headerlink" title="与tensorflow的效率比较"></a>与tensorflow的效率比较</h3><p>使用MAE损失函数</p><div class="table-container"><table><thead><tr><th style="text-align:left">Horizon</th><th style="text-align:center">Tensorflow</th><th style="text-align:center">Pytorch</th></tr></thead><tbody><tr><td style="text-align:left">1 Hour</td><td style="text-align:center">3.69</td><td style="text-align:center">3.12</td></tr><tr><td style="text-align:left">30 Min</td><td style="text-align:center">3.15</td><td style="text-align:center">2.82</td></tr><tr><td style="text-align:left">15 Min</td><td style="text-align:center">2.77</td><td style="text-align:center">2.56</td></tr></tbody></table></div><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>METR-LA和PEMS-BAY的数据文件, <code>metr-la.h5</code> 和 <code>pems-bay.h5</code>, 下载地址 <a href="https://pan.baidu.com/s/14Yy9isAIZYdU__OYEQGa_g">Baidu Yun</a>, 把他们放在 <code>data/</code> 文件夹.<br> <code>*.h5</code> 以 <code>panads.DataFrame</code> 格式存放数据，使用的是 <code>HDF5</code> 文件格式。数据框如下所示:</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">sensor_0</th><th style="text-align:center">sensor_1</th><th style="text-align:center">sensor_2</th><th style="text-align:center">sensor_n</th></tr></thead><tbody><tr><td style="text-align:center">2018/01/01 00:00:00</td><td style="text-align:center">60.0</td><td style="text-align:center">65.0</td><td style="text-align:center">70.0</td><td style="text-align:center">…</td></tr><tr><td style="text-align:center">2018/01/01 00:05:00</td><td style="text-align:center">61.0</td><td style="text-align:center">64.0</td><td style="text-align:center">65.0</td><td style="text-align:center">…</td></tr><tr><td style="text-align:center">2018/01/01 00:10:00</td><td style="text-align:center">63.0</td><td style="text-align:center">65.0</td><td style="text-align:center">60.0</td><td style="text-align:center">…</td></tr><tr><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td></tr></tbody></table></div><p>这是关于HDF5数据格式的参考资料： <a href="https://medium.com/@jerilkuriakose/using-hdf5-with-python-6c5242d08773">Using HDF5 with Python</a>.</p><p>运行下面命令生成 train/test/val 数据集，数据集位于 <code>data/&#123;METR-LA,PEMS-BAY&#125;/&#123;train,val,test&#125;.npz</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据集文件夹</span></span><br><span class="line">mkdir -p data/&#123;METR-LA,PEMS-BAY&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># METR-LA</span></span><br><span class="line">python -m scripts.generate_training_data --output_dir=data/METR-LA --traffic_df_filename=data/metr-la.h5</span><br><span class="line"></span><br><span class="line"><span class="comment"># PEMS-BAY</span></span><br><span class="line">python -m scripts.generate_training_data --output_dir=data/PEMS-BAY --traffic_df_filename=data/pems-bay.h5</span><br></pre></td></tr></table></figure><h2 id="运行预训练模型模型"><a href="#运行预训练模型模型" class="headerlink" title="运行预训练模型模型"></a>运行预训练模型模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># METR-LA</span></span><br><span class="line">python run_demo_pytorch.py --config_filename=data/model/pretrained/METR-LA/config.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># PEMS-BAY</span></span><br><span class="line">python run_demo_pytorch.py --config_filename=data/model/pretrained/PEMS-BAY/config.yaml</span><br></pre></td></tr></table></figure><p>DCRNN模型的预测结果位于 <code>data/results/dcrnn_predictions</code>.</p><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># METR-LA</span></span><br><span class="line">python dcrnn_train_pytorch.py --config_filename=data/model/dcrnn_la.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># PEMS-BAY</span></span><br><span class="line">python dcrnn_train_pytorch.py --config_filename=data/model/dcrnn_bay.yaml</span><br><span class="line">有可能梯度爆炸，临时的解决办法是在爆炸前中断后断点续训，或者降低学习速率。</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># METR-LA</span></span><br><span class="line">python -m scripts.eval_baseline_methods --traffic_reading_filename=data/metr-la.h5</span><br></pre></td></tr></table></figure><h3 id="PyTorch运行结果"><a href="#PyTorch运行结果" class="headerlink" title="PyTorch运行结果"></a>PyTorch运行结果</h3><p><img src="./result1.png" alt="PyTorch Results" title="PyTorch Results"></p><p><img src="./result2.png" alt="PyTorch Results" title="PyTorch Results"></p><p><img src="./result3.png" alt="PyTorch Results" title="PyTorch Results"></p><p><img src="./result4.png" alt="PyTorch Results" title="PyTorch Results"></p><h2 id="scripts文件"><a href="#scripts文件" class="headerlink" title="scripts文件"></a>scripts文件</h2><p>主要包括数据预处理的代码。</p><h3 id="gen-adj-mx-py"><a href="#gen-adj-mx-py" class="headerlink" title="gen_adj_mx.py"></a>gen_adj_mx.py</h3><p>gen_adj_mx.py是用来生成邻接矩阵的。</p><p>main函数里面首先定义了命令行参数，如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--sensor_ids_filename&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;data/sensor_graph/graph_sensor_ids.txt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;File containing sensor ids separated by comma.&#x27;</span>) </span><br></pre></td></tr></table></figure><p>其中的参数分别表示命令的名称，类型，默认值，帮助信息。 定义后就可以用定义后就可以用 <code>args.sensor_ids_filename</code> 就可以取相应的值。然后通过<code>get_adjacency_matrix</code> 函数生成邻接矩阵，最后保存到 pickle 的文件。 <code>get_adjacency_matrix(distance_df, sensor_ids, normalized_k=0.1)</code> 具体的解释:</p><ol><li><p>初始化: <code>dist_mx</code>的大小为<code>[num_sensors,num_sensors]</code>其中 <code>(num_sensors = len(sensor_ids))</code>，初始值为<code>inf</code>(无限大)</p></li><li><p>构建传感器id到索引映射:遍历所有对象 <code>sensor_ids</code> ，将每一个<code>i</code> 填充至<code>sensor_id_to_ind[sensor_id]</code> ，即 <code>sensor_id_to_ind[sensor_id] = i</code>。</p></li><li><p>用距离填充矩阵中的单元格:遍历所有<code>distance_df.values</code> ，从 <code>sensor_id_to_ind[row[0]]</code>( <code>from</code> )到<code>sensor_id_to_ind[row[1]]</code>(<code>to</code> )，填充<code>row[2]</code> (<code>distance</code> )。</p></li><li><p>对 <code>dist_mx</code> 进行归一化，以减少计算量;对于稀疏性，将低于阈值(例如k)的项设置为零，</p><p>如: <code>adj_mx[adj_mx &lt; normalized_k] = 0</code></p></li></ol><h3 id="generate-training-data-py"><a href="#generate-training-data-py" class="headerlink" title="generate_training_data.py"></a>generate_training_data.py</h3><p>generate_training_data.py是用来生成训练数据的。</p><ol><li><p>以1小时为统计间隔，记录每天的间隔小时数<code>time_in_day</code> ，并添加到 <code>data_list</code></p></li><li><p>以1天为统计间隔，记录每周的间隔天数 <code>day_in_week</code> ，并添加到 <code>data_list</code></p></li><li><p>在补偿之后的时间范围内<code>(range(min_t,max_t))</code>，记录每天的时间特征指标到<code>x</code>，<code>y</code></p></li><li><p>将数据写入npz文件( <code>num_test = 6831</code> )使用最后的6831示例作为测试，其中1/8用于验证，</p><p>其余7/8用于训练。</p></li></ol><p><img src="./图片 2.png" alt=""></p><h3 id="model文件"><a href="#model文件" class="headerlink" title="model文件"></a>model文件</h3><p>模型总体框架如下图所示，总体是一个encoder-decoder结构，encoder和decoder里面各包含有两个 RNNCell，每个RNNCell包含有64个units，每个units里面包含207个结点(传感器个数)。其中用到了 scheduled sampling，即每次以一定的概率用模型的预测值作为下一个cell的输入进行预测，并且这个 概率值随着时间增大。GO是初始化为全0的矩阵，即第一次用模型的预测值作为下一个cell的输入进行预 测的时候是取全0的值作为输入。</p><p><img src="./Fig2.JPG" alt="Fig2"></p><h4 id="dcrnn-supervisor-py"><a href="#dcrnn-supervisor-py" class="headerlink" title="dcrnn_supervisor.py"></a>dcrnn_supervisor.py</h4><p><img src="./sup.png" alt="sup"></p><p>用于管理整个训练过程(从输入到输出)，即定义整个图。定义了一个DCRNNSupervisor类，它保存了 训练过程的参数，定义了记录训练状态的logging，然后将数据放入DCRNN模型中进行处理，得到结果后计算损失，获得梯度，进行梯度裁剪，更新梯度，保存参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DCRNNSupervisor</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类名: DCRNNSupervisor</span></span><br><span class="line"><span class="string">        主要成员：</span></span><br><span class="line"><span class="string">        1、log:初始化能记录、打印log的self.__logger类</span></span><br><span class="line"><span class="string">        2、data:加载数据集的类，该类包括Dataloader和scaler</span></span><br><span class="line"><span class="string">        3、节点数，输入特征向量维度，输入步长，输出维度，输出步长。</span></span><br><span class="line"><span class="string">        4、是否使用课程式学习 参考资料 https://blog.csdn.net/qq_30219017/article/details/89090690</span></span><br><span class="line"><span class="string">        5、实例化的DCRNN模型</span></span><br><span class="line"><span class="string">        主要方法：</span></span><br><span class="line"><span class="string">        1、train(self, **kwargs) 该方法将外部的参数与内部合并起来并调用_train(**kwargs)</span></span><br><span class="line"><span class="string">        2、evaluate(self, dataset=&#x27;val&#x27;, batches_seen=0) 将模型变为评估模式，迭代测试集计算准确率和损失值</span></span><br><span class="line"><span class="string">        3、_train(self, base_lr,</span></span><br><span class="line"><span class="string">               steps, patience=50, epochs=100, lr_decay_ratio=0.1, log_every=1, save_model=1,</span></span><br><span class="line"><span class="string">               test_every_n_epochs=10, epsilon=1e-8, **kwargs)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>(1)类初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, adj_mx, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    函数名: __init__</span></span><br><span class="line"><span class="string">    函数功能描述: 初始化DCRNNSupervisor成员</span></span><br><span class="line"><span class="string">    函数参数: 邻接矩阵和kwargs</span></span><br><span class="line"><span class="string">    函数返回值: NULL</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self._kwargs = kwargs<span class="comment">#kwargs是传入的yaml文件内的参数该文件保存了data，model，train三部分信息。</span></span><br><span class="line">    self._data_kwargs = kwargs.get(<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    self._model_kwargs = kwargs.get(<span class="string">&#x27;model&#x27;</span>)</span><br><span class="line">    self._train_kwargs = kwargs.get(<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.max_grad_norm = self._train_kwargs.get(<span class="string">&#x27;max_grad_norm&#x27;</span>, <span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对log类初始化</span></span><br><span class="line">    self._log_dir = self._get_log_dir(kwargs)</span><br><span class="line">    self._writer = SummaryWriter(<span class="string">&#x27;runs/&#x27;</span> + self._log_dir)</span><br><span class="line"></span><br><span class="line">    log_level = self._kwargs.get(<span class="string">&#x27;log_level&#x27;</span>, <span class="string">&#x27;INFO&#x27;</span>)</span><br><span class="line">    self._logger = utils.get_logger(self._log_dir, __name__, <span class="string">&#x27;info.log&#x27;</span>, level=log_level)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对数据集信息初始化</span></span><br><span class="line">    self._data = utils.load_dataset(**self._data_kwargs)<span class="comment">#实例化dataset类</span></span><br><span class="line">    self.standard_scaler = self._data[<span class="string">&#x27;scaler&#x27;</span>]<span class="comment">#实例化标准化类</span></span><br><span class="line"></span><br><span class="line">    self.num_nodes = <span class="built_in">int</span>(self._model_kwargs.get(<span class="string">&#x27;num_nodes&#x27;</span>, <span class="number">1</span>))<span class="comment">#节点数</span></span><br><span class="line">    self.input_dim = <span class="built_in">int</span>(self._model_kwargs.get(<span class="string">&#x27;input_dim&#x27;</span>, <span class="number">1</span>))<span class="comment">#输入特征向量维度</span></span><br><span class="line">    self.seq_len = <span class="built_in">int</span>(self._model_kwargs.get(<span class="string">&#x27;seq_len&#x27;</span>))  <span class="comment"># 输入序列步长</span></span><br><span class="line">    self.output_dim = <span class="built_in">int</span>(self._model_kwargs.get(<span class="string">&#x27;output_dim&#x27;</span>, <span class="number">1</span>)) <span class="comment">#输出维度</span></span><br><span class="line">    self.use_curriculum_learning = <span class="built_in">bool</span>(</span><br><span class="line">      self._model_kwargs.get(<span class="string">&#x27;use_curriculum_learning&#x27;</span>, <span class="literal">False</span>))<span class="comment">#是否使用课程学习</span></span><br><span class="line">    self.horizon = <span class="built_in">int</span>(self._model_kwargs.get(<span class="string">&#x27;horizon&#x27;</span>, <span class="number">1</span>))  <span class="comment">#输出序列步长</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># setup model</span></span><br><span class="line">    dcrnn_model = DCRNNModel(adj_mx, self._logger, **self._model_kwargs)<span class="comment">#DCRNN模型实例化</span></span><br><span class="line">    self.dcrnn_model = dcrnn_model.cuda() <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> dcrnn_model</span><br><span class="line">    self._logger.info(<span class="string">&quot;Model created&quot;</span>)</span><br><span class="line"></span><br><span class="line">    self._epoch_num = self._train_kwargs.get(<span class="string">&#x27;epoch&#x27;</span>, <span class="number">0</span>)<span class="comment">#训练轮数</span></span><br><span class="line">    <span class="keyword">if</span> self._epoch_num &gt; <span class="number">0</span>:</span><br><span class="line">      self.load_model()</span><br></pre></td></tr></table></figure><p>(2)训练模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_train</span>(<span class="params">self, base_lr,</span></span></span><br><span class="line"><span class="function"><span class="params">           steps, patience=<span class="number">50</span>, epochs=<span class="number">100</span>, lr_decay_ratio=<span class="number">0.1</span>, log_every=<span class="number">1</span>, save_model=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">           test_every_n_epochs=<span class="number">10</span>, epsilon=<span class="number">1e-8</span>, **kwargs</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    函数名: _train</span></span><br><span class="line"><span class="string">    函数功能描述: 训练流程</span></span><br><span class="line"><span class="string">    函数参数: steps, patience=50, epochs=100, lr_decay_ratio=0.1, log_every=1, save_model=1,</span></span><br><span class="line"><span class="string">           test_every_n_epochs=10, epsilon=1e-8, **kwargs</span></span><br><span class="line"><span class="string">    函数返回值: NULL</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># steps is used in learning rate - will see if need to use it?</span></span><br><span class="line">    min_val_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    wait = <span class="number">0</span></span><br><span class="line">    optimizer = torch.optim.Adam(self.dcrnn_model.parameters(), lr=base_lr, eps=epsilon)<span class="comment">#定义adam优化器</span></span><br><span class="line"></span><br><span class="line">    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=steps,</span><br><span class="line">                                                        gamma=lr_decay_ratio)<span class="comment">#按需调整学习率 MultiStepLR 调整学习率的一些小tips https://liumin.blog.csdn.net/article/details/85143614</span></span><br><span class="line"></span><br><span class="line">    self._logger.info(<span class="string">&#x27;Start training ...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this will fail if model is loaded with a changed batch_size</span></span><br><span class="line">    num_batches = self._data[<span class="string">&#x27;train_loader&#x27;</span>].num_batch<span class="comment">#训练批次数</span></span><br><span class="line">    self._logger.info(<span class="string">&quot;num_batches:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(num_batches))</span><br><span class="line"></span><br><span class="line">    batches_seen = num_batches * self._epoch_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch_num <span class="keyword">in</span> <span class="built_in">range</span>(self._epoch_num, epochs):</span><br><span class="line"></span><br><span class="line">        self.dcrnn_model = self.dcrnn_model.train()<span class="comment">#模型设置为训练模式</span></span><br><span class="line"></span><br><span class="line">        train_iterator = self._data[<span class="string">&#x27;train_loader&#x27;</span>].get_iterator()<span class="comment">#获取生成训练集的迭代器</span></span><br><span class="line">        losses = []</span><br><span class="line"></span><br><span class="line">        start_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iterator):</span><br><span class="line">            optimizer.zero_grad()<span class="comment">#清空梯度</span></span><br><span class="line"></span><br><span class="line">            x, y = self._prepare_data(x, y)<span class="comment">#数据预处理</span></span><br><span class="line"></span><br><span class="line">            output = self.dcrnn_model(x, y, batches_seen)<span class="comment">#前向传播</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> batches_seen == <span class="number">0</span>:</span><br><span class="line">              <span class="comment"># this is a workaround to accommodate dynamically registered parameters in DCGRUCell</span></span><br><span class="line">                optimizer = torch.optim.Adam(self.dcrnn_model.parameters(), lr=base_lr, eps=epsilon)<span class="comment">#定义adam优化器</span></span><br><span class="line"></span><br><span class="line">                loss = self._compute_loss(y, output)<span class="comment">#计算损失函数</span></span><br><span class="line"></span><br><span class="line">                self._logger.debug(loss.item())</span><br><span class="line"></span><br><span class="line">                losses.append(loss.item())<span class="comment">#记录损失函数</span></span><br><span class="line"></span><br><span class="line">                batches_seen += <span class="number">1</span></span><br><span class="line">                loss.backward()<span class="comment">#反向传播</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># gradient clipping - this does it in place</span></span><br><span class="line">                torch.nn.utils.clip_grad_norm_(self.dcrnn_model.parameters(), self.max_grad_norm)<span class="comment">#梯度裁剪</span></span><br><span class="line"></span><br><span class="line">                optimizer.step()<span class="comment">#更新参数</span></span><br><span class="line">                self._logger.info(<span class="string">&quot;epoch complete&quot;</span>)</span><br><span class="line">                lr_scheduler.step()<span class="comment">#更新学习率</span></span><br><span class="line">                self._logger.info(<span class="string">&quot;evaluating now!&quot;</span>)</span><br><span class="line"></span><br><span class="line">                val_loss, _ = self.evaluate(dataset=<span class="string">&#x27;val&#x27;</span>, batches_seen=batches_seen)<span class="comment">#评估验证集</span></span><br><span class="line"></span><br><span class="line">                end_time = time.time()</span><br><span class="line"></span><br><span class="line">                self._writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>,</span><br><span class="line">                                        np.mean(losses),</span><br><span class="line">                                        batches_seen)</span><br><span class="line"><span class="comment">#写入log信息 保存验证集上最小损失的模型</span></span><br><span class="line">                <span class="keyword">if</span> (epoch_num % log_every) == log_every - <span class="number">1</span>:</span><br><span class="line">                    message = <span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;] (&#123;&#125;) train_mae: &#123;:.4f&#125;, val_mae: &#123;:.4f&#125;, lr: &#123;:.6f&#125;, &#x27;</span> \</span><br><span class="line">                    <span class="string">&#x27;&#123;:.1f&#125;s&#x27;</span>.<span class="built_in">format</span>(epoch_num, epochs, batches_seen,</span><br><span class="line">                                     np.mean(losses), val_loss, lr_scheduler.get_lr()[<span class="number">0</span>],</span><br><span class="line">                                     (end_time - start_time))</span><br><span class="line">                    self._logger.info(message)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (epoch_num % test_every_n_epochs) == test_every_n_epochs - <span class="number">1</span>:</span><br><span class="line">                        test_loss, _ = self.evaluate(dataset=<span class="string">&#x27;test&#x27;</span>, batches_seen=batches_seen)</span><br><span class="line">                        message = <span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;] (&#123;&#125;) train_mae: &#123;:.4f&#125;, test_mae: &#123;:.4f&#125;,  lr: &#123;:.6f&#125;, &#x27;</span> \</span><br><span class="line">                        <span class="string">&#x27;&#123;:.1f&#125;s&#x27;</span>.<span class="built_in">format</span>(epoch_num, epochs, batches_seen,</span><br><span class="line">                                         np.mean(losses), test_loss, lr_scheduler.get_lr()[<span class="number">0</span>],</span><br><span class="line">                                         (end_time - start_time))</span><br><span class="line">                        self._logger.info(message)</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> val_loss &lt; min_val_loss:</span><br><span class="line">                            wait = <span class="number">0</span></span><br><span class="line">                            <span class="keyword">if</span> save_model:</span><br><span class="line">                                model_file_name = self.save_model(epoch_num)</span><br><span class="line">                                self._logger.info(</span><br><span class="line">                                  <span class="string">&#x27;Val loss decrease from &#123;:.4f&#125; to &#123;:.4f&#125;, &#x27;</span></span><br><span class="line">                                  <span class="string">&#x27;saving to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(min_val_loss, val_loss, model_file_name))</span><br><span class="line">                                min_val_loss = val_loss</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">elif</span> val_loss &gt;= min_val_loss:</span><br><span class="line">                                    wait += <span class="number">1</span></span><br><span class="line">                                    <span class="keyword">if</span> wait == patience:</span><br><span class="line">                                        self._logger.warning(<span class="string">&#x27;Early stopping at epoch: %d&#x27;</span> % epoch_num)</span><br><span class="line">                                        <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>(3)评估模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">self, dataset=<span class="string">&#x27;val&#x27;</span>, batches_seen=<span class="number">0</span></span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   函数名: evaluate</span></span><br><span class="line"><span class="string">   函数功能描述: 评估模型</span></span><br><span class="line"><span class="string">   函数参数:  dataset=&#x27;val&#x27;, batches_seen=0</span></span><br><span class="line"><span class="string">   函数返回值: NULL</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    self.dcrnn_model = self.dcrnn_model.<span class="built_in">eval</span>()<span class="comment">#评估模式</span></span><br><span class="line"></span><br><span class="line">    val_iterator = self._data[<span class="string">&#x27;&#123;&#125;_loader&#x27;</span>.<span class="built_in">format</span>(dataset)].get_iterator()<span class="comment">#生成数据集</span></span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    y_truths = []</span><br><span class="line">    y_preds = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_iterator):</span><br><span class="line">      x, y = self._prepare_data(x, y)<span class="comment">#数据预处理</span></span><br><span class="line"></span><br><span class="line">      output = self.dcrnn_model(x)<span class="comment">#前向传播</span></span><br><span class="line">      loss = self._compute_loss(y, output)<span class="comment">#计算损失函数</span></span><br><span class="line">      losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">      y_truths.append(y.cpu())<span class="comment">#记录标签</span></span><br><span class="line">      y_preds.append(output.cpu())<span class="comment">#记录预测值</span></span><br><span class="line"></span><br><span class="line">      mean_loss = np.mean(losses)</span><br><span class="line"></span><br><span class="line">      self._writer.add_scalar(<span class="string">&#x27;&#123;&#125; loss&#x27;</span>.<span class="built_in">format</span>(dataset), mean_loss, batches_seen)</span><br><span class="line"></span><br><span class="line">      y_preds = np.concatenate(y_preds, axis=<span class="number">1</span>)</span><br><span class="line">      y_truths = np.concatenate(y_truths, axis=<span class="number">1</span>)  <span class="comment"># 在batch_size维拼接</span></span><br><span class="line"></span><br><span class="line">      y_truths_scaled = []</span><br><span class="line">      y_preds_scaled = []</span><br><span class="line">      <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(y_preds.shape[<span class="number">0</span>]):</span><br><span class="line">        y_truth = self.standard_scaler.inverse_transform(y_truths[t])</span><br><span class="line">        y_pred = self.standard_scaler.inverse_transform(y_preds[t])</span><br><span class="line">        y_truths_scaled.append(y_truth)</span><br><span class="line">        y_preds_scaled.append(y_pred)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mean_loss, &#123;<span class="string">&#x27;prediction&#x27;</span>: y_preds_scaled, <span class="string">&#x27;truth&#x27;</span>: y_truths_scaled&#125;</span><br></pre></td></tr></table></figure><h4 id="dcrnn-model-py"><a href="#dcrnn-model-py" class="headerlink" title="dcrnn_model.py"></a>dcrnn_model.py</h4><p>这部分调用了两次DCGRUCell，它分别返回了一个cell和一个cell_with_projection(最后一层cell要进行 预测，需要将维度变为预测值的维度)，定义了一个encoder(包含两个cell)和decoder(包含一个cell 和一个cell_with_projection)。每个RNNcell由64个units构成，每个units有207个结点。</p><p><img src="./model.png" alt="model"></p><p>(1)Seq2Seq模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqAttrs</span>:</span><span class="comment">#定义父类，初始化Seq2Seq模型各项参数</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类名: Seq2SeqAttrs</span></span><br><span class="line"><span class="string">        主要成员：</span></span><br><span class="line"><span class="string">        1、邻接矩阵</span></span><br><span class="line"><span class="string">        2、随机游走步长</span></span><br><span class="line"><span class="string">        3、卷积核类型</span></span><br><span class="line"><span class="string">        4、节点数</span></span><br><span class="line"><span class="string">        5、rnn层数</span></span><br><span class="line"><span class="string">        6、rnn单元数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, adj_mx, **model_kwargs</span>):</span></span><br><span class="line">        self.adj_mx = adj_mx</span><br><span class="line">        self.max_diffusion_step = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;max_diffusion_step&#x27;</span>, <span class="number">2</span>))</span><br><span class="line">        self.cl_decay_steps = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;cl_decay_steps&#x27;</span>, <span class="number">1000</span>))</span><br><span class="line">        self.filter_type = model_kwargs.get(<span class="string">&#x27;filter_type&#x27;</span>, <span class="string">&#x27;laplacian&#x27;</span>)</span><br><span class="line">        self.num_nodes = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;num_nodes&#x27;</span>, <span class="number">1</span>))</span><br><span class="line">        self.num_rnn_layers = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;num_rnn_layers&#x27;</span>, <span class="number">1</span>))</span><br><span class="line">        self.rnn_units = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;rnn_units&#x27;</span>))</span><br><span class="line">        self.hidden_state_size = self.num_nodes * self.rnn_units</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>(2)EncoderModel模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderModel</span>(<span class="params">nn.Module, Seq2SeqAttrs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类名: EncoderModel</span></span><br><span class="line"><span class="string">        主要成员：</span></span><br><span class="line"><span class="string">        1、输入维度</span></span><br><span class="line"><span class="string">        2、序列长度</span></span><br><span class="line"><span class="string">        3、dcgru层[dcgrucell , dcgrucell ... dcgrucell]</span></span><br><span class="line"><span class="string">        主要方法：</span></span><br><span class="line"><span class="string">        1、forward(self, inputs, hidden_state=None)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, adj_mx, **model_kwargs</span>):</span></span><br><span class="line">        nn.Module.__init__(self)</span><br><span class="line">        Seq2SeqAttrs.__init__(self, adj_mx, **model_kwargs)</span><br><span class="line">        self.input_dim = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;input_dim&#x27;</span>, <span class="number">1</span>))<span class="comment">#输入维度</span></span><br><span class="line">        self.seq_len = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;seq_len&#x27;</span>))  <span class="comment"># 输入encoder时间步</span></span><br><span class="line">        self.dcgru_layers = nn.ModuleList(</span><br><span class="line">            [DCGRUCell(self.rnn_units, adj_mx, self.max_diffusion_step, self.num_nodes,</span><br><span class="line">                       filter_type=self.filter_type) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.num_rnn_layers)])<span class="comment">#一个循环层堆叠两个DCGRU单元</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, hidden_state=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Encoder前向传播</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :参数 input: shape (batch_size, self.num_nodes * self.input_dim)</span></span><br><span class="line"><span class="string">        :参数 hidden_states: (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">               optional, zeros if not provided</span></span><br><span class="line"><span class="string">        :返回值: output: # shape (batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">                hidden_states # shape (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">                 (lower indices mean lower layers)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size, _ = inputs.size()</span><br><span class="line">        <span class="keyword">if</span> hidden_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            hidden_state = torch.zeros((self.num_rnn_layers, batch_size, self.hidden_state_size),</span><br><span class="line">                                       device=device)<span class="comment">#最开始没有输出值作为特征向量与输入值融合，故使用0向量</span></span><br><span class="line">        hidden_states = []</span><br><span class="line">        output = inputs</span><br><span class="line">        <span class="comment">#循环迭代两个DCGRU单元</span></span><br><span class="line">        <span class="keyword">for</span> layer_num, dcgru_layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.dcgru_layers):</span><br><span class="line">            next_hidden_state = dcgru_layer(output, hidden_state[layer_num])</span><br><span class="line">            hidden_states.append(next_hidden_state)</span><br><span class="line">            output = next_hidden_state</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, torch.stack(hidden_states)  <span class="comment"># 时间复杂度 O(num_layers) 将迭代的特征向量按时间步顺序堆叠</span></span><br></pre></td></tr></table></figure><p>(3)DecoderModel模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderModel</span>(<span class="params">nn.Module, Seq2SeqAttrs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类名: EncoderModel</span></span><br><span class="line"><span class="string">        主要成员：</span></span><br><span class="line"><span class="string">        1、输出维度</span></span><br><span class="line"><span class="string">        2、输出序列长度</span></span><br><span class="line"><span class="string">        3、全连接层</span></span><br><span class="line"><span class="string">        3、dcgru层[dcgrucell , dcgrucell ... dcgrucell]</span></span><br><span class="line"><span class="string">        主要方法：</span></span><br><span class="line"><span class="string">        1、forward(self, inputs, hidden_state=None)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, adj_mx, **model_kwargs</span>):</span></span><br><span class="line">        <span class="comment"># super().__init__(is_training, adj_mx, **model_kwargs)</span></span><br><span class="line">        nn.Module.__init__(self)</span><br><span class="line">        Seq2SeqAttrs.__init__(self, adj_mx, **model_kwargs)</span><br><span class="line">        self.output_dim = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;output_dim&#x27;</span>, <span class="number">1</span>))</span><br><span class="line">        self.horizon = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;horizon&#x27;</span>, <span class="number">1</span>))  <span class="comment"># for the decoder</span></span><br><span class="line">        self.projection_layer = nn.Linear(self.rnn_units, self.output_dim)</span><br><span class="line">        self.dcgru_layers = nn.ModuleList(</span><br><span class="line">            [DCGRUCell(self.rnn_units, adj_mx, self.max_diffusion_step, self.num_nodes,</span><br><span class="line">                       filter_type=self.filter_type) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.num_rnn_layers)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, hidden_state=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        解码器前向传播。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :参数 input: shape (batch_size, self.num_nodes * self.output_dim)</span></span><br><span class="line"><span class="string">        :参数 hidden_states: (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">               optional, zeros if not provided</span></span><br><span class="line"><span class="string">        :返回值: output: # shape (batch_size, self.num_nodes * self.output_dim)</span></span><br><span class="line"><span class="string">                hidden_states # shape (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">                 (lower indices mean lower layers)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        hidden_states = []</span><br><span class="line">        output = inputs</span><br><span class="line">        <span class="comment">#循环迭代两个DCGRU单元</span></span><br><span class="line">        <span class="keyword">for</span> layer_num, dcgru_layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.dcgru_layers):</span><br><span class="line">            next_hidden_state = dcgru_layer(output, hidden_state[layer_num])</span><br><span class="line">            hidden_states.append(next_hidden_state)</span><br><span class="line">            output = next_hidden_state</span><br><span class="line">        <span class="comment">#为保证output和标签维度相同，使用一层全连接网络作为投影层，投影至和标签维度相同</span></span><br><span class="line">        projected = self.projection_layer(output.view(-<span class="number">1</span>, self.rnn_units))</span><br><span class="line">        output = projected.view(-<span class="number">1</span>, self.num_nodes * self.output_dim)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, torch.stack(hidden_states)</span><br></pre></td></tr></table></figure><p>(4)DCRNNModel模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DCRNNModel</span>(<span class="params">nn.Module, Seq2SeqAttrs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类名: DCRNNModel</span></span><br><span class="line"><span class="string">        主要成员：</span></span><br><span class="line"><span class="string">        1、编码器</span></span><br><span class="line"><span class="string">        2、解码器</span></span><br><span class="line"><span class="string">        主要方法：</span></span><br><span class="line"><span class="string">        1、encoder(self, inputs)</span></span><br><span class="line"><span class="string">        2、decoder(self, encoder_hidden_state, labels=None, batches_seen=None)</span></span><br><span class="line"><span class="string">        3、forward(self, inputs, labels=None, batches_seen=None)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, adj_mx, logger, **model_kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        Seq2SeqAttrs.__init__(self, adj_mx, **model_kwargs)</span><br><span class="line">        self.encoder_model = EncoderModel(adj_mx, **model_kwargs)</span><br><span class="line">        self.decoder_model = DecoderModel(adj_mx, **model_kwargs)</span><br><span class="line">        self.cl_decay_steps = <span class="built_in">int</span>(model_kwargs.get(<span class="string">&#x27;cl_decay_steps&#x27;</span>, <span class="number">1000</span>))</span><br><span class="line">        self.use_curriculum_learning = <span class="built_in">bool</span>(model_kwargs.get(<span class="string">&#x27;use_curriculum_learning&#x27;</span>, <span class="literal">False</span>))</span><br><span class="line">        self._logger = logger</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encoder</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        向编码器循环输入t个时间步的特征向量</span></span><br><span class="line"><span class="string">        :参数 input: shape (seq_len, batch_size, num_sensor * input_dim)</span></span><br><span class="line"><span class="string">        :返回: encoder_hidden_state: (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        encoder_hidden_state = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(self.encoder_model.seq_len):<span class="comment">#循环迭代seq_len步</span></span><br><span class="line">            _, encoder_hidden_state = self.encoder_model(inputs[t], encoder_hidden_state)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> encoder_hidden_state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decoder</span>(<span class="params">self, encoder_hidden_state, labels=<span class="literal">None</span>, batches_seen=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        向解码器循环输入t个时间步的特征向量</span></span><br><span class="line"><span class="string">        :参数 encoder_hidden_state: (num_layers, batch_size, self.hidden_state_size)</span></span><br><span class="line"><span class="string">        :参数 labels: (self.horizon, batch_size, self.num_nodes * self.output_dim)</span></span><br><span class="line"><span class="string">        :参数 batches_seen: global step [optional, not exist for inference]</span></span><br><span class="line"><span class="string">        :返回值: output: (self.horizon, batch_size, self.num_nodes * self.output_dim)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size = encoder_hidden_state.size(<span class="number">1</span>)</span><br><span class="line">        go_symbol = torch.zeros((batch_size, self.num_nodes * self.decoder_model.output_dim),</span><br><span class="line">                                device=device)</span><br><span class="line">        decoder_hidden_state = encoder_hidden_state</span><br><span class="line">        decoder_input = go_symbol<span class="comment">#在第一个时间步没有任何预测结果，使用纯0向量作为预测的开始</span></span><br><span class="line"></span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(self.decoder_model.horizon):<span class="comment">#循环迭代horizon步</span></span><br><span class="line">            decoder_output, decoder_hidden_state = self.decoder_model(decoder_input,</span><br><span class="line">                                                                      decoder_hidden_state)</span><br><span class="line">            decoder_input = decoder_output<span class="comment">#上一步输出作为下一步输入</span></span><br><span class="line">            outputs.append(decoder_output)</span><br><span class="line">            <span class="keyword">if</span> self.training <span class="keyword">and</span> self.use_curriculum_learning:<span class="comment">#课程学习 https://zhuanlan.zhihu.com/p/81455004</span></span><br><span class="line">                c = np.random.uniform(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> c &lt; self._compute_sampling_threshold(batches_seen):<span class="comment">#按照一定的概率决定是否选择标签</span></span><br><span class="line">                    decoder_input = labels[t]</span><br><span class="line">        outputs = torch.stack(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, labels=<span class="literal">None</span>, batches_seen=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Seq2Seq模型前向传播</span></span><br><span class="line"><span class="string">        :参数 inputs: shape (seq_len, batch_size, num_sensor * input_dim)</span></span><br><span class="line"><span class="string">        :参数 labels: shape (horizon, batch_size, num_sensor * output)</span></span><br><span class="line"><span class="string">        :参数 batches_seen: batches seen till now</span></span><br><span class="line"><span class="string">        :返回值: output: (self.horizon, batch_size, self.num_nodes * self.output_dim)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        encoder_hidden_state = self.encoder(inputs)</span><br><span class="line">        self._logger.debug(<span class="string">&quot;Encoder complete, starting decoder&quot;</span>)</span><br><span class="line">        outputs = self.decoder(encoder_hidden_state, labels, batches_seen=batches_seen)</span><br><span class="line">        self._logger.debug(<span class="string">&quot;Decoder complete&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> batches_seen == <span class="number">0</span>:</span><br><span class="line">            self._logger.info(</span><br><span class="line">                <span class="string">&quot;Total trainable parameters &#123;&#125;&quot;</span>.<span class="built_in">format</span>(count_parameters(self))</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h4 id="dcrnn-cell-py"><a href="#dcrnn-cell-py" class="headerlink" title="dcrnn_cell.py"></a>dcrnn_cell.py</h4><p>dcrnn_cell实现了论文中的DCGRU，它将卷积融合到了GRU里面。具体结构如下:</p><p><img src="./cell.png" alt="cell"></p><p>它实现了论文中的如下部分：</p><p><img src="./1.png" style="zoom:70%;" /></p><p>(1)实现初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_units, adj_mx, max_diffusion_step,num_nodes,num_proj=<span class="literal">None</span>,activation=tf.nn.tanh,reuse=<span class="literal">None</span>, filter_type=<span class="string">&quot;laplacian&quot;</span>,use_gc_for_ru=<span class="literal">True</span></span>):</span></span><br></pre></td></tr></table></figure><p>该函数实现了GRU模块成员变量的初始化，包括units数量，路网图距离权重邻接矩阵，扩散步数，节点数量。输入参数num_units表示每个cell中units的数量，参与后面state_size(self,)，output_size(self)的计算；输入参数adj_mx对应速度检测站之间的归一化后的距离权重邻接矩阵；输入参数max_diffusion_step表示允许的最大随机游走的步数；输入参数num_nodes表示速度检测站节点的数量；输入参数num_proj 代表预测结果的数量（如num_proj=1表示预测1个结果，num_proj=2表示预测2个结果）。如果num_proj不为空（None），即到了最后一层cell_with_projection，GRU模块在计算后会进行预测。</p><p>(2)实现基于图卷积的随机游走函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gconv</span>(<span class="params">self, inputs, state, output_size, bias_start=<span class="number">0.0</span></span>):</span></span><br><span class="line">  <span class="comment"># 把输入和特征向量转换成 (batch_size, num_nodes, input_dim/state_dim)</span></span><br><span class="line">  batch_size = inputs.shape[<span class="number">0</span>]</span><br><span class="line">  inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -<span class="number">1</span>))</span><br><span class="line">  state = torch.reshape(state, (batch_size, self._num_nodes, -<span class="number">1</span>))</span><br><span class="line">  inputs_and_state = torch.cat([inputs, state], dim=<span class="number">2</span>)</span><br><span class="line">  input_size = inputs_and_state.size(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">  x = inputs_and_state</span><br><span class="line">  x0 = x.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)  <span class="comment"># (num_nodes, total_arg_size, batch_size)</span></span><br><span class="line">  x0 = torch.reshape(x0, shape=[self._num_nodes, input_size * batch_size])</span><br><span class="line">  x = torch.unsqueeze(x0, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> self._max_diffusion_step == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">for</span> support <span class="keyword">in</span> self._supports:</span><br><span class="line">      x1 = torch.sparse.mm(support, x0)</span><br><span class="line">      x = self._concat(x, x1)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, self._max_diffusion_step + <span class="number">1</span>):</span><br><span class="line">        x2 = <span class="number">2</span> * torch.sparse.mm(support, x1) - x0</span><br><span class="line">        x = self._concat(x, x2)</span><br><span class="line">        x1, x0 = x2, x1</span><br><span class="line"></span><br><span class="line">        num_matrices = <span class="built_in">len</span>(self._supports) * self._max_diffusion_step + <span class="number">1</span></span><br><span class="line">        x = torch.reshape(x, shape=[num_matrices, self._num_nodes, input_size, batch_size])</span><br><span class="line">        x = x.permute(<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)  <span class="comment"># (batch_size, num_nodes, input_size, order)</span></span><br><span class="line">        x = torch.reshape(x, shape=[batch_size * self._num_nodes, input_size * num_matrices])</span><br><span class="line"></span><br><span class="line">        weights = self._gconv_params.get_weights((input_size * num_matrices, output_size))</span><br><span class="line">        x = torch.matmul(x, weights)  <span class="comment"># (batch_size * self._num_nodes, output_size)</span></span><br><span class="line"></span><br><span class="line">        biases = self._gconv_params.get_biases(output_size, bias_start)</span><br><span class="line">        x += biases</span><br><span class="line">        <span class="comment"># 把结果转换成 2D: (batch_size, num_node, state_dim) -&gt; (batch_size, num_node * state_dim)</span></span><br><span class="line">        <span class="keyword">return</span> torch.reshape(x, [batch_size, self._num_nodes * output_size])</span><br></pre></td></tr></table></figure><p>这里实现了论文中的扩散卷积方法。首先将input和state拼接为input_state，即论文中的，将input_state和random_walk_mx进行max_diffusion_step次图卷积，结果是max_diffusion_step步随机游走的结果，然后用将乘以一个weights矩阵把维度变换为output_size。首先对input和state进行计算，对计算结果进行nn.sigmoid()激活。这里的和为GRU模型中的reset_gate和update_gate。然后计算GRU核，如果存在激活函数，则。计算新的输出和状态 ，除非到了最后一层cell_with_projection，否则output总是和new_state是一样的。判断是否需要输出预测值，如果不需要，则直接返回output，new_state。如果需要进行预测，将output乘以一个w矩阵将维度变换为output_size，最后返回output，new_state。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;总体框架&quot;&gt;&lt;a href=&quot;#总体框架&quot; class=&quot;headerlink&quot; title=&quot;总体框架&quot;&gt;&lt;/a&gt;总体框架&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;data存放模型用到的数据。其中METR-LA和PEMS-BAY文件夹存放的是scripts中generate_training_data.py生成的数据，model保存的是训练好的模型及其设置参数，sensor_graph保存的是传感器的数据，其中graph_sensor_ids.txt保存了所有数据中所使用的传感器的id，distances_la_2012.csv以csv格式保存了传感器之间的距离。metr-la.h5和pems-bay.h5是两个城市的交通数据。&lt;/li&gt;
&lt;li&gt;figures文件存放的是模型总体结构的图片。&lt;/li&gt;
&lt;li&gt;lib文件包含模型用到的工具函数、优化算法和评价指标。&lt;/li&gt;
&lt;li&gt;model文件中dcrnn_supervisor.py是训练过程中控制整个训练流程的文件，dcrnn_model.py定义了dcrnn模型，dcrnn_cell.py定义了模型中的cell单元，其中实现了核心的扩散卷积。&lt;/li&gt;
&lt;li&gt;scripts包含数据预处理代码，其中gen_adj_mx.py用于生成图的邻接矩阵，generate_training_data.py用于生成训练、验证和测试数据。&lt;/li&gt;
&lt;li&gt;dcrnn_train_pytorch.py是用来训练模型的，run_demo_pytorch.py是用来跑一下已经训练好的模型。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="代码解析" scheme="https://leezepeng.github.io/categories/%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="交通流" scheme="https://leezepeng.github.io/tags/%E4%BA%A4%E9%80%9A%E6%B5%81/"/>
    
    <category term="代码解析" scheme="https://leezepeng.github.io/tags/%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>交通流Seq2Seq12篇</title>
    <link href="https://leezepeng.github.io/2021/03/13/%E4%BA%A4%E9%80%9A%E6%B5%81Seq2Seq12%E7%AF%87/"/>
    <id>https://leezepeng.github.io/2021/03/13/%E4%BA%A4%E9%80%9A%E6%B5%81Seq2Seq12%E7%AF%87/</id>
    <published>2021-03-13T12:05:56.000Z</published>
    <updated>2021-03-14T12:50:26.895Z</updated>
    
    <content type="html"><![CDATA[<h2 id="论文汇总表"><a href="#论文汇总表" class="headerlink" title="论文汇总表"></a>论文汇总表</h2><span id="more"></span><div class="table-container"><table><thead><tr><th>论文名</th><th>创新点</th><th>属于交通哪一类问题</th><th>节点V 及含义</th><th>边E及含义</th><th>邻接矩阵A及每一个a的含义</th><th>特征矩阵X及含义</th><th>GNNS</th><th>RNNS</th><th>其他方法</th></tr></thead><tbody><tr><td>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic  Forecasting</td><td>1.道路的权重是变化的，也就是道路网的边之间有相互的影响   2.使用GCN的时候只考虑了一个范围，比如这个范围是k跳邻居节点。</td><td>交通流量预测模型</td><td>传感器</td><td>传感器i到j构成一条边</td><td>一个node-wise两个edge-wides</td><td>每个传感器的特征，与数据集有关</td><td>Bicomponent Graph Convolution</td><td>GRU</td><td>Multi-Range Attention</td></tr><tr><td>A deep learning approach considering spatio-temporal dependencies</td><td>为了捕获多步交通状况预测中复杂的非平稳时间动态和空间相关性</td><td>交通流量预测模型</td><td>节点集N表示路口传感器或高速公路上选定的分界点</td><td>链路集L表示路段</td><td>稀疏矩阵A为链路集的邻接矩阵，虚拟变量A (i, j)表示链路i与链路j是否连通</td><td>数据集自带特征V 以及Time-of-day and weekday-or-weekend，Historical statistic information</td><td>GCN</td><td>GRU</td><td>注意力机制</td></tr><tr><td>STG2Seq: Spatial-Temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting</td><td>预测多个时刻的乘客需求由于时空依赖的非线性和动态性</td><td>交通需求预测模型</td><td>N个小区域</td><td>根据区域间旅客需求模式的相似性定义图的边</td><td>相似度</td><td>所有区域在时间 的旅客需求以及包含了几点、星期几以及节假日的信息。</td><td>Gated Graph Convolutional Module</td><td>Long-term and Short-term Encoders</td><td>注意力机制</td></tr><tr><td>Spatio-Temporal Graph Convolutional and Recurrent Networks for Citywide Passenger Demand Prediction</td><td>预测多个时刻的乘客需求由于时空依赖的非线性和动态性</td><td>交通需求预测模型</td><td>N个小区域</td><td>根据区域间旅客需求模式的相似性定义图的边</td><td>相似度</td><td>所有区域在时间 的旅客需求以及包含了几点、星期几以及节假日的信息。</td><td>GCN</td><td>LSTM</td><td>无</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>论文名</th><th>创新点</th><th>属于交通哪一类问题</th><th>节点V 及含义</th><th>边E及含义</th><th>邻接矩阵A及每一个a的含义</th><th>特征矩阵X及含义</th><th>GNNS</th><th>RNNS</th><th>其他方法</th></tr></thead><tbody><tr><td>Dual Graph for Traffic Forecasting</td><td>同时考虑了道路节点和边的信息</td><td>流量预测</td><td>路口</td><td>道路</td><td>有边就为1，没有就为0</td><td>流量</td><td></td><td>1</td><td></td></tr><tr><td>GMAN: A Graph Multi-Attention Network for Traffic Prediction</td><td>时空注意力，transform注意力里用时空特征缓解了误差传播</td><td>流量预测</td><td>传感器</td><td>连通性</td><td>节点的proximity</td><td>流量加时空特征</td><td></td><td>1</td><td>MAE，RMSE，MAPE</td></tr><tr><td>GCGAN: Generative Adversarial Nets with Graph CNN for Network-Scale Traffic Prediction</td><td>GAN</td><td>流量预测</td><td>路段</td><td>连通性</td><td>节点的proximity</td><td>流量</td><td></td><td>1</td><td>注意力公式用的是Gumbel-Softmax</td></tr><tr><td>Learning Dynamic Graph Embedding for Traffic Flow Forecasting:A Graph Self-Attentive Method</td><td>自注意力</td><td>流量预测</td><td>传感器</td><td>连通性</td><td>节点的proximity</td><td>流量</td><td></td><td>1</td><td>MAE，RMSE，MAPE</td></tr></tbody></table></div><h1 id="multi-Range-attentive-GCN-for-交通预测"><a href="#multi-Range-attentive-GCN-for-交通预测" class="headerlink" title="multi-Range attentive GCN for 交通预测"></a>multi-Range attentive GCN for 交通预测</h1><h2 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h2><p>作者认为即使使用GCN仍然有一些问题</p><ol><li><p>道路的权重是变化的，也就是道路网的边之间有相互的影响，比如下图（c）中的两个边之间有影响。</p></li><li><p>使用GCN的时候只考虑了一个范围，比如这个范围是k跳邻居节点。</p></li></ol><p><img src="./image-20201115163854907.png" alt="image-20201115163854907" style="zoom:50%;" /></p><p>作者认为考虑多个范围是有必要的，也就是局部和全局两个角度，从一般的角度比如（1,2,3,…..,k）跳邻居，然后使用attention的方式考虑节点各跳的权重比，最后使用了RNN来建模时序关系，主要就是使用前面GCN处理后的特征作为RNN的输入。使用了两个数量集，METR-LA and PEMS-BAY。</p><h2 id="整体架构图"><a href="#整体架构图" class="headerlink" title="整体架构图"></a>整体架构图</h2><p><img src="./截屏2020-11-15 下午8.32.45.png" alt="截屏2020-11-15 下午8.32.45" style="zoom:50%;" /></p><p>然后我们先看下设计的整体架构图，这里没有包含时域的RNN模块。主要包含了输入的两个部分，一个是node-wise的，一个是edge-wise的网络，两个网络进行卷积，同时还设计了一个multi-range的attention (k-hops)，然后使用attention的方式考虑v各个hop之间的权重比，最后经过时序处理(RNN)之后输出。</p><h2 id="Bicomponent-Graph-Convolution"><a href="#Bicomponent-Graph-Convolution" class="headerlink" title="Bicomponent Graph Convolution"></a>Bicomponent Graph Convolution</h2><p>考虑我们前面说的第一个问题，就是路网的边之间的影响，这里作者总结了两中影响关系，如下图所示：</p><p><img src="./截屏2020-11-17 下午12.20.07.png" alt="截屏2020-11-17 下午12.20.07" style="zoom:50%;" /></p><h3 id="流连接关系"><a href="#流连接关系" class="headerlink" title="流连接关系"></a>流连接关系</h3><p>$\begin{array}{c}<br>\boldsymbol{A}_{e,(i \rightarrow j),(j \rightarrow k)}=\boldsymbol{A}_{e,(j \rightarrow k),(i \rightarrow j)}=<br>\exp \left(-\frac{\left(\mathrm{deg}^{-}(j)+\mathrm{deg}^{+}(j)-2\right)^{2}}{\sigma^{2}}\right)<br>\end{array}$</p><h3 id="竞争关系"><a href="#竞争关系" class="headerlink" title="竞争关系"></a>竞争关系</h3><p>$\begin{array}{l}<br>\boldsymbol{A}_{e,(i \rightarrow k),(j \rightarrow k)}=\boldsymbol{A}_{e,(j \rightarrow k),(i \rightarrow k)}=<br>\exp \left(-\frac{\left(\mathrm{deg}^{+}(i)+\operatorname{deg}^{+}(j)-2\right)^{2}}{\sigma^{2}}\right)<br>\end{array}$</p><p><strong>在一个交通网络中，一个道路链路可能会受到其上下游道路链路的影响。如图a所示,(𝑖→𝑗)是 (𝑗→𝑘)的上游,因此它们是相关的。直观地说,如果联合节点𝑗有大量的邻居， (𝑖→𝑗)和(𝑗→𝑘)之间的关系就会较弱,容易受到其他邻居影响。我们计算流连接的边𝑨使用高斯核函数。竞争关系同理：共享同一源节点的道路链路可能会争夺交通资源，形成竞争关系。如图3 (b),两条边,(𝑖→𝑘)和(𝑗→𝑘),共享目标节点𝑘相关是由于竞争关系。与流连接类似，竞争关系的强度与源节点的度有关。如，如果一条边的源节点有多个输出边，则该边对于流量资源的竞争是非常强的。当然针对这种不同的图有作者自定义的卷积操作。</strong></p><p>这里的A就是我们卷积边网络时候的连接矩阵，根据不同的关系我们重新构造连接矩阵，然后我们构造一个K跳的的graph conv。</p><p>$\begin{array}{c}<br>\boldsymbol{X}^{(l+1)}=\boldsymbol{\theta}_{n \star G}^{(l)}\left[\boldsymbol{X}^{(l)}, \boldsymbol{M Z}^{(l)}\right] \text { for } l=1, \cdots, k-1, \\<br>\boldsymbol{Z}^{(l+1)}=\boldsymbol{\theta}_{e \star G}^{(l)}\boldsymbol{Z}^{(l)} \quad \text { for } l=0, \cdots, k-1 \\<br>\boldsymbol{X}^{(1)}=\boldsymbol{\theta}_{n \star G}^{(0)} \boldsymbol{X}^{(0)} \\<br>\boldsymbol{Z}^{(0)}=\boldsymbol{M}^{\mathrm{T}} \boldsymbol{X}^{(0)} \boldsymbol{W}_{\mathrm{b}}<br>\end{array}$</p><p>⋆ 这是图卷积的标志， ,( → )= ,( → )=1 and 0 otherwise表示连接关系。</p><p>X表示监测的交通流量，所以 ={ (1), (2 ),⋯, ( k)},共考虑了k跳</p><p><strong>M矩阵是一个线性变换 把节点信息编码成边的信息Z0，Z0经过一层边卷积同时节点进过一层节点卷积，最后利用M矩阵变换回来，把边信息与节点信息融合再做一次节点卷积。这就是整个卷积的过程。</strong></p><p>Attention使用的目的主要是为了应对不同range之间如何融合的问题。multi-range attention mechanism转化为公式就是：</p><p>$\begin{array}{c}<br>e_{i}^{(l)}=\left(W_{\mathrm{a}} X_{i}^{(l)}\right)^{\mathrm{T}} \boldsymbol{u} \\<br>a_{i}^{(l)}=\operatorname{SoftMax}_{l}\left(e_{i}^{(l)}\right)=\frac{\exp \left(e_{i}^{(l)}\right)}{\sum_{l=1}^{k} \exp \left(e_{i}^{(l)}\right)}<br> \\<br>\boldsymbol{h}_{i}=\sum_{l=1}^{k} a_{i}^{(l)} \boldsymbol{X}_{i}^{(l)}<br>\end{array}$</p><p>最后这个就是常规操作了，我们上面已经考虑了空间的依赖关系，主要依靠图卷积进行学习，下面考虑的就是时间上的卷积。我们将空间卷积的结果直接作为RNN的输入就ok了</p><p>$\begin{aligned}<br>\boldsymbol{z}^{(t)} &amp;=\sigma\left(g\left(\left[\boldsymbol{X}^{(t)}, \boldsymbol{H}^{(t-1)}\right] ; \boldsymbol{\Theta}_{z}\right)\right) \\<br>\boldsymbol{r}^{(t)} &amp;=\sigma\left(g\left(\left[\boldsymbol{X}^{(t)}, \boldsymbol{H}^{(t-1)}\right] ; \boldsymbol{\theta}_{r}\right)\right) \\<br>\boldsymbol{C}^{(t)}=&amp; \tanh \left(g\left(\left[\boldsymbol{X}^{(t)},\left(\boldsymbol{r}^{(t)} \odot \boldsymbol{H}^{(t-1)}\right)\right] ; \boldsymbol{\Theta}_{c}\right)\right) \\<br>\boldsymbol{H}^{(t)} &amp;=\boldsymbol{z}^{(t)} \odot \boldsymbol{H}^{(t-1)}+\left(1-\mathbf{z}^{(t)}\right) \odot \boldsymbol{C}^{(t)}<br>\end{aligned}$</p><p>这个是我们预测的架构，一般我们需要的就是X5.</p><p><img src="./截屏2020-11-17 下午12.39.55.png" alt="截屏2020-11-17 下午12.39.55" style="zoom:50%;" /></p><h1 id="Multistep-speed-prediction-on-traffic-networks-A-deep-learning-approach-considering-spatio-temporal-dependencies"><a href="#Multistep-speed-prediction-on-traffic-networks-A-deep-learning-approach-considering-spatio-temporal-dependencies" class="headerlink" title="Multistep speed prediction on traffic networks: A deep learning approach considering spatio-temporal dependencies"></a>Multistep speed prediction on traffic networks: A deep learning approach considering spatio-temporal dependencies</h1><h2 id="相关工作及解决的问题"><a href="#相关工作及解决的问题" class="headerlink" title="相关工作及解决的问题"></a>相关工作及解决的问题</h2><ul><li>提出了一种新的深度学习框架AGC-Seq2Seq，该框架通过Seq2Seq模型和图形卷积层协同提取时空域的特征。克服多步预测的挑战。</li><li>为了捕捉城市交通模式的时间异质性，将注意机制进一步纳入模型。我们设计了一种新的针对多步交通预测的Seq2Seq框架的训练方法，以替代现有的训练方法(如 teacher forcing 和 scheduled sampling)。它在一个端到端深度学习结构中协调多维特征(例如历史统计信息和时间)和时空速度变量，使测试周期的输入与训练周期一致。</li><li>通过a -map提供的两个真实数据集进行验证，提出的模型在不同的预测区间内的各种主要误差度量方面比其他先进的基准有显著的改进。</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h3><p>根据行车方向将路网建模为有向图，其中节点集 $N$ 表示路口(检测器或高速公路上选定的分界点)，链路集 $L$ 表示路段，如图1所示。A为链路集的邻接矩阵，虚拟变量A (i, j)表示链路i与链路j是否连通，即</p><p>$\boldsymbol{A}(i, j)=\left\{\begin{array}{ll}<br>1, l_{i} \text { and } l_{j} \text { are connected along driving direction } \\<br>0,  \text { otherwise }<br>\end{array}\right.$</p><h3 id="特征向量"><a href="#特征向量" class="headerlink" title="特征向量"></a>特征向量</h3><ul><li>交通速度</li><li>一天中的时间和一周中的时间</li><li>历史标准信息比如平均值，中值，最大最小值。</li></ul><h2 id="什么是Teacher-Forcing"><a href="#什么是Teacher-Forcing" class="headerlink" title="什么是Teacher Forcing"></a>什么是Teacher Forcing</h2><p>所谓Teacher Forcing，就是在学习时跟着老师(ground truth)走!</p><p>它是一种网络训练方法，对于开发用于机器翻译，文本摘要，图像字幕的深度学习语言模型以及许多其他应用程序至关重要。它每次不使用上一个state的输出作为下一个state的输入，而是直接使用训练数据的标准答案(ground truth)的对应上一项作为下一个state的输入。<br>看一下大佬们对它的评价:</p><blockquote><p>存在把输出返回到模型输入中的这种循环连接单元的模型可以通过Teacher Forcing机制进行训练。</p></blockquote><p>这种技术最初被作为反向传播的替代技术进行宣传与开发</p><blockquote><p>在动态监督学习任务中经常使用的一种有趣的技术是，在计算过程中用教师信号 d(t)替换上一个单元的实际输出 y ( t )。我们称这种技术为Teacher Forcing。</p></blockquote><p>Teacher Forcing工作原理: 在训练过程的 t时刻，使用训练数据集的期望输出或实际输出: y(t)， 作为下一时间步骤的输入: x(t+1)，而不是使用模型生成的输出 h(t)。</p><blockquote><p>在训练过程中接收ground truth的输出 y(t) 作为 t+1时刻的输入</p></blockquote><h3 id="Free-Running-vs-Teacher-Forcing-实例"><a href="#Free-Running-vs-Teacher-Forcing-实例" class="headerlink" title="Free-Running vs Teacher Forcing 实例"></a>Free-Running vs Teacher Forcing 实例</h3><p>给定如下输入序列:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mary had a little lamb whose fleece was white as snow</span><br></pre></td></tr></table></figure><p>我们想要训练这样一个模型，在给定序列中前一个单词的情况下生成序列中的下一个单词。<br>那首先，我们得给这个序列的首尾加上起止token:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[START] Mary had a little lamb whose fleece was white as snow [END]</span><br></pre></td></tr></table></figure><p>接下来，我们把 “[START]” 输入模型，让模型生成下一个单词。</p><h4 id="Free-running-训练过程"><a href="#Free-running-训练过程" class="headerlink" title="Free-running 训练过程"></a>Free-running 训练过程</h4><p>想象下，现在模型生成了一个 “a”， 不过我们当然期望它先生成一个 “Mary”。</p><p><img src="./v2-c60a4531fcf6678c1f4d19ba60e2a99c_1440w.png" alt="img"></p><p>接下来，如果把”a”输入模型，来生成序列中的下一个单词，那现在的情况就是</p><p><img src="./v2-ab28faba19493d6e347753308fd36a80_1440w.png" alt="img"></p><p>可以看到，模型现在已经<strong>偏离正轨</strong> ，因为生成的错误结果，会导致后续的学习都受到不好的影响，导致学习速度变慢，模型也变得不稳定。</p><h4 id="Teacher-Forcing-训练过程"><a href="#Teacher-Forcing-训练过程" class="headerlink" title="Teacher-Forcing 训练过程"></a>Teacher-Forcing 训练过程</h4><p>假如现在模型生成了一个“a”，我们可以在计算了error之后，丢弃这个输出，把”Marry”作为后续的输入。如果要继续预测下一个单词的话，那么现在的情形就变成了:</p><p><img src="./v2-22283c8d1c18d301672ab21aaf04fb9f_1440w.png" alt="img"></p><p>以此类推，所有训练步骤情形为:</p><p><img src="./v2-df5167508190ac8be34d2a2a9322b475_1440w.jpg" alt="img"></p><p>该模型将更正模型训练过程中的统计属性，更快地学会生成正确的序列。</p><h2 id="Teacher-Forcing的缺点"><a href="#Teacher-Forcing的缺点" class="headerlink" title="Teacher Forcing的缺点"></a>Teacher Forcing的缺点</h2><p>一直靠老师带的孩子是走不远的。<br> 因为依赖标签数据，在训练过程中，模型会有较好的效果，但是在测试的时候因为不能得到ground truth的支持，所以如果目前生成的序列在训练过程中有很大不同，模型就会变得脆弱。也就是如果测试数据集与训练数据集来自不同的领域，模型的performance就会变差。</p><h2 id="Newly-designed-training-method"><a href="#Newly-designed-training-method" class="headerlink" title="Newly designed training method"></a>Newly designed training method</h2><p><img src="./image-20201124220437885.png" alt="image-20201124220437885"></p><p>为了克服上述问题，文章提出了一种新的训练方法，使用历史统计信息比如j这段时间的平均值，中位数，最大值，最小值和一周中的某天和一天中的某时作为输入。在时间序列预测问题中，在训练和测试阶段都可以获得历史统计信息在这种情况下，译码器输入在训练和测试期间的分布将会同步，从而解决了教师强迫的困境。此外，由于历史统计信息在多步预测中至关重要，将其加入到模型中有望提高预测精度。这是他的模型解决的问题。</p><h2 id="AGC-Seq2Seq模型架构"><a href="#AGC-Seq2Seq模型架构" class="headerlink" title="AGC-Seq2Seq模型架构"></a><em>AGC-Seq2Seq</em>模型架构</h2><p><img src="./截屏2020-11-18 下午7.52.36.png" alt="截屏2020-11-18 下午7.52.36"></p><p>首先将邻接矩阵和交通流速的特征向量喂入图卷积，得到m+1时刻的交通流速序列，再将交通流速序列与其他两个信息拼接起来作为特征向量，放入encoder模型，利用t-m到t+1的特征向量计算注意力值S，在decoder模型中，将注意力模型与t+1特征向量拼接融合，最后一个不带激活函数的全连接层输出。</p><h1 id="STG2Seq"><a href="#STG2Seq" class="headerlink" title="STG2Seq"></a>STG2Seq</h1><h2 id="先前工作的缺点和不足"><a href="#先前工作的缺点和不足" class="headerlink" title="先前工作的缺点和不足"></a>先前工作的缺点和不足</h2><ul><li>基于cnn的方法(包括ConvLSTM)假设将城市划分为小网格(如1km×1km面积)，这并不总是成立[Chu et al.， 2018]。此外，这些方法只能模拟邻近地区和偏远地区之间的Eu- clidean关系，而不能模拟具有相似特征的再微粒地区之间的非欧几里得相关性。考虑图1(a)中的示例。A区与D区(大学和购物区)有共同的兴趣点，而与B区和C区(包含公园)有共同的兴趣点。因此，A地区旅客需求与D的相关性强于B和C。</li><li>目前的方法严格依赖基于rnnture的架构(例如混合的CNN-LSTM和ConvLSTM架构)来捕获时间相关性。然而，典型的链结构RNN结构需要执行大量的迭代步骤(等于输入数据的窗口大小)来处理需求数据，从而导致在建模长期时间依赖性时出现严重的信息遗忘。此外，利用RNN作为多步预测的解码器会导致每一步的误差积累，导致模型更快的恶化。</li><li>目前的研究努力没有准确地捕捉到可能存在于时间相关性。其中大部分仅反映了历史旅客需求的总体影响。但是，前面的每一步可能对要预测的那一步产生不同的影响。</li></ul><h2 id="所做的工作"><a href="#所做的工作" class="headerlink" title="所做的工作"></a>所做的工作</h2><ul><li>我们将全市旅客需求用图表表示出来，并提出了一个基于gcn的多步旅客需求预测模型。据我们所知，这是第一个纯粹依靠图卷积结构来提取时空相关性进行多步预测的工作。</li><li>我们提出基于注意力的输出模块来捕捉最具影响力的历史时间步长对预测需求的影响。</li><li>我们在三个真实数据集上进行了广泛的实验，并将我们的方法与三个基线和八种基于深度学习的先进鉴别方法进行比较。实验结果表明，我们的模型能够始终显著地优于所有的比较方法。</li></ul><h2 id="Gated-Graph-Convolutional-Module"><a href="#Gated-Graph-Convolutional-Module" class="headerlink" title="Gated Graph Convolutional Module"></a>Gated Graph Convolutional Module</h2><p>GGCM 模块的详细设计如图 。第 l 个 GGCM 的输入是一个矩阵，维数为 h×N×Cl。在第一个 GGCM 模块，Cl 是 din 维的。第 l 个 GGCM 的输出是 h×N×Cl+1。我们先拼接一个 zero padding，维数为 (k−1)×N×Cl，得到新的输入 (h+k−1)×N×Cl，确保变换不会减少序列的长度。接下来，GGCM 中的每个 GCN 取 k 个时间步的数据 k×N×Cl 作为输入来提取时空关联性，然后 reshape 成一个二维矩阵 N×(k⋅Cl)。对于这个过程，立体的比较难理解，我们把它映射成平面以了解他为什么既能捕获时间信息又能捕获空间信息。</p><p><img src="./image-20201124223216810.png" alt="image-20201124223216810"></p><p>为了捕获时空关联性，每个 GCN 在一定长度的时间窗内操作(k)。它可以提取 k 个时间步内所有区域的空间关联性。通过堆叠多个 GGCM，我们的模型形成了一个层次结构，可以捕获整个输入的时空关联性。图 3 展示了只使用 GCN 捕获时空关联性，为了简化我们忽略了通道维。可以同时捕获时空关联性。</p><p><img src="./截屏2020-11-25 上午11.09.06.png" alt="截屏2020-11-25 上午11.09.06"></p><h2 id="提出新架构的原因"><a href="#提出新架构的原因" class="headerlink" title="提出新架构的原因"></a>提出新架构的原因</h2><p>1.很多之前的工作只考虑下一步预测，即预测下一时间步的旅客需求。</p><p>2.在目标需求和前一个需求上的长距离计算会导致一些信息的遗忘。</p><p>3.在解码部分，为了预测时间步 T 的需求，RNN 将隐藏状态和前一时间步 T−1 作为输入。因此，前一时间步带来的误差会直接影响到预测，导致未来时间步误差的累积。</p><h2 id="Long-term-and-Short-term-Encoders"><a href="#Long-term-and-Short-term-Encoders" class="headerlink" title="Long-term and Short-term Encoders"></a>Long-term and Short-term Encoders</h2><p><img src="./截屏2020-11-24 下午10.40.27.png" alt="截屏2020-11-24 下午10.40.27"></p><p>于是就引入Long-term and Short-term Encoders，长期编码器的输入为h步历史数据：h×n×d的3D的立方体，h为时间步，n为节点个数，din为节点特征维度。其中，长期编码器由多个GCCM模块组成，其中每个GGCM捕获所有N个区域之间的空间相关性和k（斑块大小，超参数）时间步长之间的时间相关性。h×n×d长期编码器的输出为一个的矩阵Y_h.短期编码器用来集成已经预测的需求，用于多步预测。它使用一个长度为 q 的滑动窗来捕获近期的时空关联性。当预测在 T(T∈[t+1,t+τ]) 步的旅客需求时，它取最近的 q 个时间步的旅客需求，即 {DT−q,DT−q+1,…,DT−1} 作为输入。除了时间步的长度以外，短期编码器和长期编码器一样。短期编码器生成一个维数为 q×N×dout 的矩阵 YTq 作为近期趋势表示。和基于 RNN 的解码器不同的是，RNN的解码器只将最后一个时间步的预测结果输入回去。因此，预测误差会被长期编码器减弱，缓解基于 RNN 的解码器会导致误差累积的问题。</p><h1 id="GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction"><a href="#GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction" class="headerlink" title="GMAN: A Graph Multi-Attention Network for Traffic Prediction"></a>GMAN: A Graph Multi-Attention Network for Traffic Prediction</h1><h2 id="先前工作的缺点和不足-1"><a href="#先前工作的缺点和不足-1" class="headerlink" title="先前工作的缺点和不足"></a>先前工作的缺点和不足</h2><ul><li>复杂的时空关联：<ul><li>动态的空间关联。如图所示，路网中的传感器之间的关联随时间剧烈地变化，比如高峰时段的前后。如何动态地选择相关的检测器数据来预测一个检测器在未来长时间范围的交通状况是一个挑战。</li><li>非线性的时间关联。一个检测器的交通状况可能变化得非常剧烈，且可能由于事故等因素，突然影响不同时间步之间的关联性。如何自适应地随时间的推移对这种非线性时间关联建模，也是一个挑战。</li></ul></li><li>对误差传递的敏感。长期预测上，每个时间步上小的错误都会被放大。这样的误差传递对于远期时间预测来说仍具有挑战性。</li></ul><p><img src="./截屏2020-11-25 上午11.29.00.png" style="zoom:50%;" /></p><h2 id="该工作做出的贡献"><a href="#该工作做出的贡献" class="headerlink" title="该工作做出的贡献"></a>该工作做出的贡献</h2><ul><li>提出空间注意力和时间注意力对动态空间和非线性时间关联分别建模。此外，我们设计了一个门控融合机制，自适应地融合空间注意力和时间注意力机制的的信息。</li><li>提出一个变换注意力机制将历史交通特征转换为未来的表示。这个注意力机制对历史和未来的关系直接建模，减轻错误传播的问题。</li><li>我们在两个数据集上评估了我们的图多注意力网络，在 1 小时预测问题上比 state-of-the-art 提高了 4%。</li></ul><h2 id="Graph-Multi-Attention-Network"><a href="#Graph-Multi-Attention-Network" class="headerlink" title="Graph Multi-Attention Network"></a>Graph Multi-Attention Network</h2><p><img src="./Fig2.png" alt="img" style="zoom:50%;" /></p><p>图 2 描述了我们模型的架构。编码和解码器都有 STAtt Block 和残差连接。每个 ST-Attention block 由空间注意力机制、时间注意力机制和一个门控融合组成。编码器和解码器之间有个变换注意力层。我们还通过一个时空嵌入 spatial-temporal embedding (STE) 继承了图结构和时间信息到多注意力机制中。此外，为了辅助残差连接，所有层的输出都是 D 维。</p><h2 id="Spatio-Temporal-Embedding"><a href="#Spatio-Temporal-Embedding" class="headerlink" title="Spatio-Temporal Embedding"></a>Spatio-Temporal Embedding</h2><p>因为交通状况的变化受限于路网，集成路网信息到模型中很重要。为此，我们提出一个空间嵌入，把结点嵌入到向量中以此保存图结构信息。我们利用 node2vec 学习结点表示。此外，为了协同训练模型和预学习的向量，这些向量会放入一个两层全连接神经网络中。然后就可以拿到空间表示 $e^S_{v_i} \in \mathbb{R}^D$。</p><p>空间嵌入只提供了固定的表示，不能表示路网中的传感器的动态关联性。我们提出了一个时间嵌入来把每个时间步编码到向量中。假设一天是 T 个时间步。我们使用 one-hot 编码星期、时间到 $\mathbb{R}^7$ 和 $\mathbb{R}^T$ 里面，然后拼接，得到 $\mathbb{R}^{T + 7}$。接下来，使用两层全连接映射到 $\mathbb{R}^D$。在我们的模型里面，给历史的 P 个时间步和未来的 Q 个时间步嵌入时间特征，表示为 $e^T_{t_j} \in \mathbb{R}^D$，$t_j = t_1$, $\dots, t_P$, $\dots$, $t_{P+Q}$。</p><p>为了获得随时间变化的顶点表示，我们融合了上述的空间嵌入和时间嵌入，得到时空嵌入（STE），如图 2b 所示。结点 $v_i$ 在时间步 $t_j$，STE 定义为 $e_{v_i,t_j} = e^S_{v_i} + e^T_{t_j}$。因此，N 个结点在 P + Q 的时间步里的 STE 表示为 $E \in \mathbb{R}^{(P + Q) \times N \times D}$。STE 包含图结构和时间信息。它会用在空间、时间、变换注意力机制里面。</p><h2 id="ST-Attention-Block"><a href="#ST-Attention-Block" class="headerlink" title="ST-Attention Block"></a>ST-Attention Block</h2><p>我们将第 l 个块的输入表示为 $H^{(l-1)}$，结点 $v_i$ 在时间步 $t_j$ 的隐藏状态表示为 $h^{(l-1)}_{v_i,t_j}$。第 l 块中的空间和时间注意力机制的输出表示为 $H^{(l)}_S$和 $H^{(l)}_T$，隐藏状态表示为 $hs^{(l)}_{v_i,t_j}$ 和 $ht^{(l)}_{v_i,t_j}$。门控融合后，第 l 层的输出表示为 $H^{(l)}$。</p><p>我们将非线性变换表示为：</p><p>$\tag{1}  f(x) = \text{ReLU}(x\mathbf{W} + \mathbf{b}).$</p><p><img src="./截屏2020-11-25 上午11.35.36.png" alt="截屏2020-11-25 上午11.35.36" style="zoom:50%;" /></p><p><strong>Spatial Attention</strong> 一条路的交通状况受其他路的影响，且影响不同。这样的影响是高度动态的，随时间变化。为了建模这些属性，我们设计了一个空间注意力机制动态地捕获路网中传感器间的关联性。核心点是在不同的时间步动态地给不同的结点分配权重，如图 3 所示。对于时间步 tj 的结点 vi，我们计算所有结点的带权和：</p><p>$\tag{2} hs^{(l)}_{v_i,t_j} = \sum_{v \in \mathcal{V}} \alpha_{v_i, v} \cdot h^{(l-1)}_{v,t_j},$</p><p>$\alpha_{v_i, v}$ 是结点 v 对 $v_i$ 的注意力分数，注意力分数之和为1：$\sum_{v \in \mathcal{V}} \alpha_{v_i, v} = 1$。</p><p>$α_{vi,v}$ 是结点 v 对 $v_i$ 的注意力分数，注意力分数之和为1：$\sum_{v \in \mathcal{V}} \alpha_{v_i, v} = 1$。</p><p>在一个确定的时间步，当前交通状况和路网结构能够影响传感器之间的关联性。举个例子，路上的拥挤可能极大地影响它临近路段的交通状况。受这个直觉的启发，我们考虑使用交通特征和图结构两方面来学习注意力分数。我们把隐藏状态和时空嵌入拼接起来，使用 scaled dot-product approach (Vaswani et al. 2017) 来计算结点 $v_i$ 和 v 之间的相关性：</p><p>$\tag{3} s_{v_i, v} = \frac{&lt; h^{(l-1)}_{v_i,t_j} \Vert\ e_{v_i,t_j}, h^{(l-1)}+{v,t_j}, \Vert e_{v,t_j} &gt;}{\sqrt{2D}}$</p><p>其中，$\Vert$ 表示拼接操作，$&lt; \bullet, \bullet &gt;$ 表示内积，2D 表示 $h^{(l-1)}_{v_i,t_j} \Vert e_{v_i,t_j}$ 的维度。$s_{v_i,v}$ 通过 softmax 归一化：</p><p>$\tag{4} \alpha_{v_i,v} = \frac{\text{exp}(s_{v_i,v})}{\sum_{v_r \in \mathcal{V}} \text{exp}(s_{v_i,v_r})}.$</p><p>得到注意力分数 $\alpha_{v_i,v}$ 之后，隐藏状态通过公式 2 更新。</p><p>为了稳定学习过程，我们把空间注意力机制扩展为多头注意力机制。我们拼接 K 个并行的注意力机制，使用不同的全连接映射：</p><p>$\tag{5} s^{(k)}_{v_i,v} = \frac{&lt; f^{(k)}_{s,1} (h^{(l-1)}_{v_i,t_j} \Vert e_{v_i,t_j}), f^{(k)}_{s,2} (h^{(l-1)}_{v,t_j} \Vert e_{v,t_j}) &gt;}{\sqrt{d}},$</p><p>$\tag{6} \alpha^{(k)}_{v_i,v} = \frac{\text{exp}(s^{(k)}_{v_i,v})}{\sum_{v_r \in \mathcal{V}} \text{exp}(s^{(k)}_{v_i,v_r})},$</p><p>$\tag{7} hs^{(l)}_{v_i,t_j} = \Vert^K_{k=1} \lbrace \sum_{v \in \mathcal{V}} \alpha^{(k)}_{v_i,v} \cdot f^{(k)}_{s,3}(h^{(l-1)}_{v,t_j}) \rbrace,$</p><p>其中 $f^{(k)}_{s,1}(\bullet), f^{(k)}_{s,2}(\bullet), f^{(k)}_{s,3}(\bullet)$ 表示第 k注意力头的三个不同的非线性映射，即公式 1 ，产生 d = D / K 维的输出。</p><p>当结点数 N 很大的时候，时间和内存消耗都会很大，达到 N^2 的数量级。为了解决这个限制，我们提出了组空间注意力，包含了组内注意力分数和组间注意力分数，如图 4 所示。</p><p><img src="./截屏2020-11-25 上午11.36.53.png" alt="截屏2020-11-25 上午11.36.53，" style="zoom:50%;" /></p><p>我们把 N 个结点随机划分为 G 个组，每个组包含 M = N / G 个结点，如果必要的话可以加 padding。每个组，我们使用公式 5，6，7 计算组内的注意力，对局部空间关系建模，参数是对所有的组共享的。然后，我们在每个组使用最大池化得到每个组的表示。接下来计算组间空间注意力，对组间关系建模，给每个组生成一个全局特征。局部特征和全局特征相加得到最后的输出。</p><p>组空间注意力中，我们每个时间步需要计算 $GM^2 + G^2 = NM + (N / M)^2$ 个注意力分数。通过使梯度为0，我们知道 M = \sqrt[3]{2N} 时，注意力分数的个数达到最大值 $2^{-1/3} N^{4/3} \ll N^2$。</p><p><img src="./截屏2020-11-25 上午11.37.49.png" alt="截屏2020-11-25 上午11.37.49，" style="zoom:50%;" /></p><p><strong>Temporal Attention</strong> 一个地点的交通状况和它之前的观测值有关，这个关联是非线性的。为了建模这些性质，我们设计了一个时间注意力机制，自适应地对不同时间步的非线性关系建模，如图 5 所示。可以注意到时间关联受到交通状况和对应的时间环境两者的影响。举个例子，早高峰的拥堵可能会影响交通好几个小时。因此，我们考虑交通特征和时间两者来衡量不同时间步的相关性。我们把隐藏状态和时空嵌入拼接起来，使用多头注意力计算注意力分数。对于结点 $v_i$，时间步 $t_j$ 与 t 的相关性定义为：</p><p>$\tag{8} u^{(k)}_{t_j,t} = \frac{&lt; f^{(k)}_{t,1}(h^{(l-1)}_{v_i,t_j} \Vert e_{v_i,t_j}), f^{(k)}_{t,2}(h^{(l-1)}_{v_i,t} \Vert e_{v_i,t}) &gt;}{\sqrt{d}},$</p><p>$\tag{9} \beta^{(k)}_{t_j,t} = \frac{\text{exp}(u^{(k)}_{t_j,t})}{\sum_{t_r \in \mathcal{N}_{t_j}}} \text{exp}(u^{(k)}_{t_j,t_r}),$</p><p>$u^{(k)}_{t_j,t}$ 表示时间步 t_j 和 t 之间的相关性，$\beta^{(k)}_{t_j,t}$ 是第 k 个头的注意力分数，表示时间步 t 对时间步 $t_j$ 的重要性，两个 f 是非线性变换，$\mathcal{N}_{t_j}$ 表示 $t_j$ 前的时间步的集合，即只考虑目标时间步以前的时间步，这样才有因果。一旦获得了注意力分数，时间步 $t_j$ 的结点 $v_i$ 的隐藏状态可以通过下面的公式更新：</p><p>$\tag{10} ht^{(l)}_{v_i,t_j} = \Vert^K_{k=1} \lbrace \sum_{t \in \mathcal{N}_{t_j}} \beta^{(k)}_{t_j,t} \cdot f^{(k)}_{t,3}(h^{(l-1)}_{v_i,t}) \rbrace$</p><p>f 是非线性映射。公式 8，9，10 学习到的参数对所有结点和所有时间步共享，且并行计算。</p><p><strong>Gated Fusion</strong> 一个时间步一条路上的交通状况与它自身之前的值和相邻道路上的交通状况相关。如图 2c 所示，我们设计了一个门控融合机制自适应地融合空间和时间表示。在第 l 个块，空间和时间注意力的输出表示为 $H^{(l)}_S$ 和$H^{(l)}_T$，两者的维度在编码器中是$\mathbb{R}^{P \times N \times D}$，解码器中是$\mathbb{R}^{Q \times N \times D}$。通过下式融合：</p><p>$\tag{11} H^{(l)} = z \odot H^{(l)}_S + (1 - z) \odot H^{(l)}_T,$</p><p>$\tag{12} z = \sigma(H^{(l)}_S \mathbf{W}_{z,1} + H^{(l)}_T \mathbf{W}_{z,2} + \mathbf{b}_z),$</p><p>门控融合机制自适应地控制每个时间步和结点上空间和时间依赖的流动。</p><h2 id="Transform-Attention"><a href="#Transform-Attention" class="headerlink" title="Transform Attention"></a>Transform Attention</h2><p><img src="./截屏2020-11-25 上午11.38.55.png" alt="截屏2020-11-25 上午11.38.55 " style="zoom:50%;" /></p><p>为了减轻错误传播的问题，我们在编码器和解码器之间加入了一个变换注意力层。它能直接地对历史时间步和未来时间步的关系建模，将交通特征编码为未来的表示，作为解码器的输入。如图 6 所示，对于结点 v_i 来说，预测的时间步 $t_j \ (t_j = t_{P+1}, \dots, t_{P+Q})$ 和历史的时间步 $t \ (t_1, \dots, t_P)$ 通过时空嵌入来衡量：</p><p>$\tag{13} \lambda^{(k)}_{t_j,t} = \frac{&lt; f^{(k)}_{tr,1}(e_{v_i,t_j}), f^{(k)}_{tr,2}(e_{v_i,t}) &gt;}{\sqrt{d}},$</p><p>$\tag{14} \gamma^{(k)}_{t_j,t} = \frac{\text{exp}(\lambda^{(k)}_{t_j,t})}{\sum^{t_P}_{t_r=t_1} \text{exp}(\lambda^{(k)}_{t_j,t_r})}.$</p><p>编码的交通特征通过注意力分数 $\gamma^{(k)}_{t_j,t}$ 自适应地在历史 P 个时间步选择相关的特征，变换到解码器的输入：</p><p>$\tag{15} h^{(l)}_{v_i,t_j} = \Vert^K_{k=1} \lbrace \sum^{t_P}_{t=t_1} \gamma^{(k)}_{t_j,t} \cdot f^{(k)}_{tr,3}(h^{(l-1)}_{v_i,t}) \rbrace.$</p><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p>GMAN 是编码解码架构。在进入编码器前，历史记录 $\mathcal{X} \in \mathbb{R}^{P \times N \times C}$ 通过全连接变换到 $H^{(0)} \in \mathbb{R}^{P \times N \times D}$。然后 H^{(0)} 输入到 L 个时空注意力块组成的编码器中，产生输出 $H^{(L)} \in \mathbb{R}^{P \times N \times D}$。然后变换注意力层把编码特征从 $H^{(L)}$ 转换为 $H^{(L+1)} \in \mathbb{R}^{Q \times N \times D}$。然后 L 个时空注意力块的解码器产生输出 $H^{(2L + 1)} \in \mathbb{R}^{Q \times N \times D}$。最后，全连接层输出 Q 个时间步的预测$\hat{Y} \in \mathbb{R}^{Q \times N \times C}$。</p><p>GMAN 可以通过最小化 MAE 来优化：</p><p>$\tag{16} \mathcal{L}(\Theta) = \frac{1}{Q} \sum^{t_{P + Q}}_{t = t_P + 1} \vert Y_t - \hat{Y}_t \vert,$</p><p>$\Theta$ 表示可学习的参数。</p><h1 id="Dual-Graph-for-Traffic-Forecasting"><a href="#Dual-Graph-for-Traffic-Forecasting" class="headerlink" title="Dual Graph for Traffic Forecasting"></a>Dual Graph for Traffic Forecasting</h1><h2 id="先前工作的缺点和不足-2"><a href="#先前工作的缺点和不足-2" class="headerlink" title="先前工作的缺点和不足"></a>先前工作的缺点和不足</h2><ul><li>只考虑路网节点交通的预测。他们忽视边信息，无法对边流量做出预测。实际上，传感器通常位于现代城市道路网络的两侧和交叉口。这些传感器一起工作来监控车辆活动，并提供实时交通描述。交通数据的任何方面，边或节点，都不应该被忽略。因此，以往方法的预测结果对于未来的交通安全和效率是不够的。</li><li>由于节点上的交通与边缘上的交通是互补的、相互关联的，即使是在单一的节点交通预测任务中，如果没有利用边缘上的信息，预测结果的准确性也会降低。</li></ul><h2 id="该工作做出的贡献-1"><a href="#该工作做出的贡献-1" class="headerlink" title="该工作做出的贡献"></a>该工作做出的贡献</h2><ul><li>将交通预测任务重新制定为利用节点和边缘上的历史交通数据同时预测未来节点和边缘交通。我们提出了一种新的对偶图网络，称为对偶图，用于在这种新的设置下的交通预测。它是一个统一的框架，可以从一端到另一端进行训练。我们开发了一个新的对偶映射块来交互地学习节点特征和边缘特征。对偶映射块采用消息传递机制来表征信息流在路网节点和边之间的传播行为。作为特例，传统的只有节点流量输入和预测的交通预测仍然可以通过我们的DualGraph来实现。</li><li>我们使用仿真城市交通(SUMO)软件来模拟从道路网络节点和边缘的传感器收集的真实交通数据。通过消融研究，验证了该方法的有效性。此外，我们在公共交通数据集metro -la和Pems-Bay上评估我们的方法，这些数据集只包含高速公路边的交通数据。我们的模型实现了最新的结果。特别是，我们的方法在较长时间(一小时)的预测中比较的方法有很大的优势。</li></ul><h2 id="DUAL-GRAPH"><a href="#DUAL-GRAPH" class="headerlink" title="DUAL GRAPH"></a>DUAL GRAPH</h2><p><img src="./截屏2020-11-25 下午3.13.39.png" alt="截屏2020-11-25 下午3.13.39" style="zoom:50%;" /></p><p>个人理解其节点和边上均有传感器，而当传感器在十字路口，转角，等有多个不同道路汇聚的地方就定义为了节点，而道路中间的传感器就定义为了边，这样就使得图上的节点和边的确有各自独立的特征。</p><p>第一步首先是节点向边传递信息，肯定不能直接传递的呀，因为节点和边的个数不同，纬度都不对，这就要引入一个公式：</p><p>$\Delta \mathcal{X}_{e}=A G G_{\mathcal{E}}\left(\left\{\phi\left(\mathcal{X}_{v}\right) \mid v \in \mathcal{V}(e)\right\}\right)$</p><p>$\mathcal{V}(e)$表示与e这条边相连的节点，一条边那肯定就是对应了两个节点，$\mathcal{X}_{v}$表示某一个，仅仅是一个节点的特征，这个特征的维度为$ \mathbb{R}^{T^{\prime} \times C_{1}}$边的特征向量也是$\mathbb{R}^{T^{\prime} \times C_{1}}$。其中T‘代表一段时刻，$\phi$是一个全连接层，这个全连接层没有激活函数，输入和输出纬度相同，AGG是定义的一个消息传递函数，这个函数带有<strong>最大池化或者平均池化</strong>操作，我们把整个操作翻译成语言：</p><p>首先将一条边的两个节点（1条边对应2个节点）的特征输入全连接层输出纬度不变$\mathbb{R}^{2 \times T^{\prime} \times C_{1}}$</p><p>然后将结果进行池化得到结果$\Delta \mathcal{X}_{e}$，纬度变为$\mathbb{R}^{T^{\prime} \times C_{1}}$（变成了一一对应）</p><p>将结果与对应边的特征向量以一定比例相加就完成了消息传递的操作。</p><p>其实实现的时候和分配矩阵相差无几，分配矩阵就相当于把节点的特征向量做了个带可学习参数的加权求和使得两个纬度变成了一个纬度，这里是池化的操作把两个纬度池化成一个纬度。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;论文汇总表&quot;&gt;&lt;a href=&quot;#论文汇总表&quot; class=&quot;headerlink&quot; title=&quot;论文汇总表&quot;&gt;&lt;/a&gt;论文汇总表&lt;/h2&gt;</summary>
    
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/categories/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/tags/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    <category term="交通流" scheme="https://leezepeng.github.io/tags/%E4%BA%A4%E9%80%9A%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>论文解读-DCRNN</title>
    <link href="https://leezepeng.github.io/2021/03/13/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-DCRNN/"/>
    <id>https://leezepeng.github.io/2021/03/13/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-DCRNN/</id>
    <published>2021-03-13T09:10:17.000Z</published>
    <updated>2021-03-14T12:50:36.365Z</updated>
    
    <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>交通预测的挑战：1. 对路网复杂的空间依赖关系， 2. 路况变换与非线性的时间动态性， 3. 长期预测的困难性。我们提出了在有向图上对交通流以扩散形式进行建模的方法，介绍了 <em>Diffusion Convolutional Recurrent Neural Network</em>(DCRNN)，用于交通预测的深度学习框架，同时集成了交通流中的空间与时间依赖。DCRNN 使用图上的双向随机游走捕获了空间依赖，使用编码解码框架以及 scheduled sampling 捕获时间依赖。我们在两个真实的交通数据集上评估了模型，比 state-of-the-art 强了12%-15%。</p><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h1><span id="more"></span><p>对一个在动态系统中运行的学习系统来说，时空预测是一个很关键的任务。自动驾驶、电网优化、供应链管理等都是它的应用。我们研究了一个重要的任务：路网上的交通预测，这是智能交通系统中的核心部分。目标是给定历史车速与路网数据，预测未来的车速。</p><p>任务有挑战性的原因是复杂的时空依赖关系以及长期预测的上的难度。一方面，交通数据序列表现出了强烈的时间动态性(temporal dynamics)。反复的事件如高峰期或交通事故导致了数据的非平稳性，使得长期预测很困难。另一方面，路网上的监测器包含了复杂但是唯一的空间联系(spatial correlations)。图1展示了一个例子。路1和路2是相关联的，但是路1和路3没有关联。尽管路1和路3在欧氏空间中很近，但是他们表现出了不同的形式。此外，未来的车速更容易受到下游交通的影响，而非上游。这就意味着交通上的空间结构不是欧氏空间的，而是有向的。</p><p><img src="./fig/Fig1.JPG" alt="Fig1"></p><p>交通预测已经研究了几十年，有两个主要类别：知识驱动的方法和数据驱动的方法。在运输和操作研究中，知识驱动的方法经常使用排队论，模拟交通中的用户行为(Cascetta, 2013)。时间序列社区中，数据驱动的方法如 Auto-Regressive Integrated Moving Average(ARIMA) 模型，Kalman filtering 还是很流行的(Liu et al., 2011; Lippi et al., 2013)。然而，简单的时间序列模型通常依赖平稳假设，这经常与实际交通数据不符。最近开始在交通预测上应用深度学习模型 (Lv et al., 2015; Yu et al., 2017b) ，但是没有考虑空间结构。Wu &amp; Tan 2016和Ma et al. 2017 使用 CNN 对空间关系进行建模，但是在欧氏空间中的。Bruna et al. 2014，Defferrard et al. 2016 研究了图卷积，但是只能处理无向图。</p><p>我们使用一个有向图来表示 pair-wise spatial correlations。图的顶点是sensors，边是权重，通过路网上 sensor 之间的距离得到。我们使用扩散卷积 (diffusion convolution) 操作来捕获空间依赖关系，以扩散性是对交通流的动态性建模。提出了 <em>Diffusion Convolutional Recurrent Neural Network</em>(DCRNN)，整合了 <em>diffusion convolution</em> 和 <em>sequence to sequence</em> 架构以及 <em>scheduled sampling</em> 技术。在真实数据集上衡量模型时，DCRNN 比state-of-the-art好很多。<br>· 我们研究了交通预测问题，在有向图上对交通的空间依赖以扩散形式建模。提出了 <em>diffusion convolution</em>，有着直观的解释以及高效的计算。<br>· 我们提出了 <em>Diffusion Convolutional Recurrent Neural Network</em> (DCRNN)，使用 <em>diffusion convolution</em>，<em>sequence to sequence</em>，<em>scheduled sampling</em> 同时对时间和空间依赖关系进行捕获的方法。DCRNN 不限于运输领域，可以应用到其他的时空预测问题上。<br>· 做了很多实验，效果很好。</p><h1 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2 Methodology"></a>2 Methodology</h1><h2 id="2-1-Traffic-Forecasting-Problem"><a href="#2-1-Traffic-Forecasting-Problem" class="headerlink" title="2.1 Traffic Forecasting Problem"></a>2.1 Traffic Forecasting Problem</h2><p>$N$ 个sensors。检测器网络表示成带权有向图 $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \boldsymbol{W})$，$\mathcal{V}$ 是顶点集，$\vert \mathcal{V} \vert = N$，$\mathcal{E}$ 是边集，$\boldsymbol{W} \in \mathbb{R}^{N \times N}$ 是带权邻接矩阵，表示顶点相似性（如路网距离的一个函数）。图信号矩阵$\boldsymbol{X} \in \mathbb{R}^{N \times P}$，$P$ 是每个顶点的特征数。$\boldsymbol{X}^{(t)}$ 表示时间 $t$ 观测到的图信号，交通预测问题目的是学习一个函数 $h(\cdot)$，将 $T’$ 个历史的图信号映射到未来的 $T$ 个图信号上，给定图 $\mathcal{G}$:</p><h2 id="2-2-Spatial-Dependency-Modeling"><a href="#2-2-Spatial-Dependency-Modeling" class="headerlink" title="2.2 Spatial Dependency Modeling"></a>2.2 Spatial Dependency Modeling</h2><p>扩散形式以 $\mathcal{G}$ 上的随机游走来刻画，重启概率 $\alpha \in [0, 1]$，状态转移矩阵 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$。这里，$\boldsymbol{D}_{\boldsymbol{O}} = \mathrm{diag}(\boldsymbol{W1})$ 是出度的对角矩阵，$\mathbf{1} \in \mathbb{R}^N$ 表示所有都为1的向量。多个时间步之后，Markov process 会收敛到平稳分布 $\mathcal{P} \in \mathbb{R}^{N \times N}$上，第 $i$ 行 $\mathcal{P}_{i,:} \in \mathbb{R}^N$ 表示从顶点 $v_i \in \mathcal{V}$ 扩散的可能性，也就是对顶点 $v_i$ 的 proximity。下面的引理是平稳分布的闭式解。</p><p><strong>Lemma 2.1</strong> (Teng et al., 2016) 扩散过程的平稳分布可以表示为图上的无限随机游走的带权组合，可以通过以下式子计算：</p><p>其中 $k$ 是diffusion step。实际上，我们使用有限的 $K$ 阶扩散过程，给每一步分配一个可训练的权重。我们也融入反向扩散过程，因为双向扩散可以让模型更灵活地去捕获上游和下游交通带来的影响。</p><p><strong>Diffusion Convolution</strong> 图信号 $\boldsymbol{X} \in \mathbb{R}^{N \times P}$ 和滤波器 $f_\theta$ 的扩散卷积操作的结果是：</p><p>其中 $\theta \in \mathbb{R}^{K \times 2}$ 表示卷积核参数，$\boldsymbol{D}^{-1}_O \boldsymbol{W}$ 和 $\boldsymbol{D}^{-1}_I \boldsymbol{W}^T$ 表示扩散过程和反向扩散的转移概率矩阵。一般，计算卷积是很耗时的。然而，如果 $\mathcal{G}$ 是稀疏的，式2可以通过递归的复杂度为 $O(K)$ 的sparse-dense矩阵乘法高效的计算，总时间复杂度为 $O(K \vert \mathcal{E} \vert) \ll O(N^2)$。附录B有详细的描述。</p><p><strong>Diffusion Convolutional Layer</strong> 式2定义的卷积操作，我们可以构建一个扩散卷积层，将 $P$ 维特征映射到 $Q$ 维输出上。将参数表示为 $\mathbf{\Theta} \in \mathbb{R}^{Q \times P \times K \times 2} = [ \boldsymbol{\theta} ]_{q, p}$，其中 $\mathbf{\Theta}_{q,p,:,:} \in \mathbb{R}^{K \times 2}$ 是第 $p$ 个输入和 $q$ 个输出的参数。扩散卷积层为：</p><p>其中，$\boldsymbol{X} \in \mathbb{R}^{N \times P}$ 是输入，$\boldsymbol{H} \in \mathbb{R}^{N \times Q}$ 是输出，$\lbrace f_{\mathbf{\Theta}_{q,p,:,:}} \rbrace $ 是滤波器，$a$ 是激活函数。扩散卷积层学习图结构数据的表示，我们可以使用基于随机梯度的方法训练它。</p><p><strong>Relation with Spectral Graph Convolution:</strong> 扩散卷积是定义在有向和无向图上的。当使用在无向图上时，我们发现很多现存的图结构卷积操作，包括流行的普图卷积，ChebNet，可以看作是一个扩散卷积的特例。令 $\boldsymbol{D}$ 表示度矩阵，$\boldsymbol{L} = \boldsymbol{D}^{-\frac{1}{2}}(\boldsymbol{D} - \boldsymbol{W}) \boldsymbol{D}^{-\frac{1}{2}}$ 是图归一化的拉普拉斯矩阵，接下来的Proposition解释了连接。</p><p><strong>Proposition 2.2.</strong> 谱图卷积的定义：</p><p>特征值分解 $\boldsymbol{L} = \Phi \Lambda \Phi^T$，当图 $\mathcal{G}$是无向图时，$F(\boldsymbol{\theta}) = \sum^{K-1}_0 \theta_k \Lambda^k$，等价于图的扩散卷积。<br>证明见后记C。</p><h2 id="2-3-Temporal-Dynamics-Modeling"><a href="#2-3-Temporal-Dynamics-Modeling" class="headerlink" title="2.3 Temporal Dynamics Modeling"></a>2.3 Temporal Dynamics Modeling</h2><p>我们利用 RNN 对时间依赖建模。我们使用 GRU，简单有效的 RNN 变体。我们将 GRU 中的矩阵乘法换成了扩散卷积，得到了我们的扩散卷积门控循环单元 <em>Diffusion Convolutional Gated Recurrent Unit(DCGRU)</em>.</p><p>其中 $\boldsymbol{X}^{(t)}, \boldsymbol{H}^{(t)}$ 表示时间 $t$ 的输入和输出，$\boldsymbol{r}^{(t)}, \boldsymbol{u}^{(t)}$ 表示时间 $t$ 的reset gate和 update gate。$\star_\mathcal{G}$ 表示式2中定义的混合卷积，$\mathbf{\Theta}_r, \mathbf{\Theta}_u, \mathbf{\Theta}_C$ 表示对应的滤波器的参数。类似 GRU，DCGRU 可以用来构建循环神经网络层，使用 BPTT 训练。</p><p><img src="./fig/Fig2.JPG" alt="Fig2"></p><p>在多步预测中，我们使用 <em>Sequence to Sequence</em> 架构。编码解码器都是 DCGRU。训练时，我们把历史的时间序列放到编码器，使用最终状态初始化解码器。解码器生成预测结果。测试时，ground truth 替换成模型本身生成的预测结果。训练和测试输入的分布的差异会导致性能的下降。为了减轻这个问题的影响，我们使用了 <em>scheduled sampling</em> (Bengio et al., 2015)，在训练的第 $i$ 轮时，模型的输入要么是概率为 $\epsilon_i$ 的 ground truth，要么是概率为 $1 - \epsilon_i$ 的预测结果。在训练阶段，$\epsilon_i$ 逐渐的减小为0，使得模型可以学习到测试集的分布。</p><p>图2展示了 DCRNN 的架构。整个网络通过 BPTT 循环生成目标时间序列的最大似然得到。DCRNN 可以捕获时空依赖关系，应用到多种时空预测问题上。</p><h1 id="3-Related-Work"><a href="#3-Related-Work" class="headerlink" title="3 Related Work"></a>3 Related Work</h1><p>运输领域和运筹学中交通预测是传统问题，主要依赖于排队论和仿真(Drew, 1968)。数据驱动的交通预测方法最近受到了很多的关注，详情可以看近些年的 paper (Vlahogianni et al., 2014)。然而，现存的机器学习模型要么有着很强的假设（如 auto-regressive model ）要么不能考虑非线性的时间依赖（如 latent space model Yu et al. 2016; Deng et al. 2016）。深度学习模型为解决时间序列预测问题提供了新的方法。举个例子，在 Yu et al. 2017b; Laptev et al. 2017 的工作中，作者使用深度循环神经网络研究时间序列预测问题。卷积神经网络已经被应用到交通预测上。Zhang et al. 2016; 2017 将路网转换成了 2D 网格，使用传统的 CNN 预测人流。Cheng et al. 2017 提出了DeepTransport，通过对每条路收集上下游邻居路段对空间依赖建模，在这些邻居上分别使用卷积操作。</p><p>最近，CNN 基于谱图理论已经泛化到任意的图结构上。图卷积神经网络由 Bruna et al. 2014 首次提出，在深度神经网络和谱图理论之间建立了桥梁。Defferrard et al. 2016 提出了 ChebNet，使用快速局部卷积滤波器提升了 GCN。Kipf &amp; Welling 2017 简化了 ChebNet，在半监督分类任务上获得了 state-of-the-art 的表现。Seo et al. 2016 融合了 ChebNet 和 RNN 用于结构序列建模。Yu et al. 2017a 对检测器网络以无向图的形式，使用 Chebnet 和卷积序列模型 (Gehring et al. 2017) 进行建模做预测。这些提及的基于谱的理论的限制之一是，他们需要图是无向的，来计算有意义的谱分解。从谱域到顶点域，Atwood &amp; Towsley 2016 提出了扩散卷积神经网络 (DCNN)，以图结构中每个顶点的扩散过程定义了卷积。Hechtlinger et al. 2017 提出了 GraphCNN 对每个顶点的 $p$ 个最近邻邻居进行卷积，将卷积泛化到图上。然而，这些方法没有考虑时间的动态性，主要处理的是静态图。</p><p>我们的方法不同于这些方法，因为问题的设定不一样，而且图卷积的公式不同。我们将 sensor network 建立成一个带权有向图，比网格和无向图更真实。此外，我们提出的卷积操作使用双向图随机游走来定义，集成了序列到序列模型以及 scheduled sampling ，对长时间的时间依赖建模。</p><h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a>4 Experiments</h1><p>我们在两个数据集上做了实验：（1）<strong>METR-LA</strong> 这个交通数据集包含了洛杉矶高速公路线圈收集的数据 (Jagadish et al., 2014)。我们选择了207个检测器，收集了从2012年3月1日到2012年6月30日4个月的数据用于实验。（2）<strong>PEMS_BAY</strong> 这个交通数据集由 California Transportation Agencies(CalTrans)Performance Measurement System (PeMS) 收集。我们选了 Bay Area 的325个检测器，收集了从2017年1月1日到2017年5月31日6个月的数据用于实验。两个数据集监测器的分布如图8所示。</p><p>这两个数据集，我们将车速聚合到了5分钟的窗口内，使用了 Z-Score normalization。70%的数用于训练，20%用于测试，10%用于验证。为了构建检测器网络，我们计算了任意两个 sensor 的距离，使用了 thresholded Gaussian kernel 来构建邻接矩阵(Shuman et al., 2013)。$W_{ij} = \exp{(-\frac{\mathrm{dist}(v_i, v_j)^2}{\sigma^2})} \ \text{if} \ \text{dist}(v_i, v_j) \leq \mathcal{\kappa}, \mathrm{otherwise} \ 0$，其中 $W_{ij}$ 表示了检测器 $v_i$ 和 $v_j$ 之间的权重，$\mathrm{dist}(v_i, v_j)$ 表示检测器 $v_i$ 到 $v_j$ 之间的距离。$\sigma$ 表示距离的标准差，$\kappa$ 表示阈值。</p><p><img src="./fig/Fig8.JPG" alt="Fig8"></p><p><img src="./fig/Table1.JPG" alt="Table1"></p><h2 id="4-1-Experimental-Settings"><a href="#4-1-Experimental-Settings" class="headerlink" title="4.1 Experimental Settings"></a>4.1 Experimental Settings</h2><p>Baselines 1. $\rm{HA}$：历史均值，将交通流建模成周期性过程，使用之前的周期的加权平均作为预测。2. $\mathrm{ARIMA}_{kal}$：Auto-Regressive Integrated Moving Average model with Kalman filter，广泛地应用于时间序列预测上。3. $\rm{VAR}$: Vector Auto-Regression(Hamilton, 1994)。4. $\rm{SVR}$：Support Vector Regression，使用线性支持向量机用于回归任务。5. Feed forward Neural network (FNN)：前向传播神经网络，两个隐藏层，L2正则化。6. Recurrent Neural Network with fully connected LSTM hidden units (FC-LSTM)(Sutskever et al., 2014).</p><p>所有的神经网络方法都是用 Tensorflow 实现，使用 Adam 优化器，学习率衰减。使用 Tree-structured Parzen Estimator(TPE)(Bergstra et al., 2011) 在验证集上选择最好的超参数。DCRNN 的详细参数设置和 baselines 的超参数设置见附录E。</p><h2 id="4-2-Traffic-Forecasting-Performance-Comparison"><a href="#4-2-Traffic-Forecasting-Performance-Comparison" class="headerlink" title="4.2 Traffic Forecasting Performance Comparison"></a>4.2 Traffic Forecasting Performance Comparison</h2><p>表1展示了不同的方法在15分钟，30分钟，1小时在两个数据集上预测的对比。这些方法在三种常用的 metrics 上进行了评估，包括1. MAE， 2. MAPE（Mean Absolute Percentage Error）， 3. RMSE。这些 metrics 中的缺失值被排除出去。这些公式在后记E.2。我们观察到这两个数据集上有以下现象：1. RNN-based methods，包括FC-LSTM和DCRNN，一般比其他的方法表现得好，这强调对时间依赖的建模的重要性。2. DCRNN在所有的 forecasting horizons 中的所有 metrics 上都获得了最好的表现，这说明对空间依赖建模的有效性。3. 深度学习模型，包括 FNN，FC-LSTM，DCRNN 在长期预测上，倾向于比线性的 baseline 有更好的结果。比如，1小时。这是因为随着 horizon 的增长，时间依赖变得更加非线性。此外，随着历史均值不依赖短期数据，它的表现对于 forecasting horizon 的小增长是不变的。</p><p>需要注意的是，METR-LA（Los Angeles，有很复杂的交通环境）数据比 PEMS-BAY 更有挑战性，所以我们将 METR-LA 的数据作为以下实验的默认数据集。</p><h2 id="4-3-Effect-of-Spatial-Dependency-Modeling"><a href="#4-3-Effect-of-Spatial-Dependency-Modeling" class="headerlink" title="4.3 Effect of Spatial Dependency Modeling"></a>4.3 Effect of Spatial Dependency Modeling</h2><p>为了继续深入对空间依赖建模的影响，我们对比了 DCRNN 和以下变体： 1. DCRNN-NoConv，这个通过使用单位阵替换扩散卷积（式2）中的转移矩阵，忽略了空间依赖。这就意味着预测只能通过历史值预测。 2. DCRNN-UniConv，扩散卷积中只使用前向随机游走；图3展示了这三个模型使用大体相同数量的参数时的学习曲线。没有扩散卷积，DCRNN-NoConv 有着更大的 validation error。此外，DCRNN获得了最低的 validation error，说明了使用双向随机游走的有效性。这个告诉我们双向随机游走赋予了模型捕获上下游交通影响的能力与灵活性。</p><p><img src="./fig/Fig3.JPG" alt="Fig3"></p><p>为了研究图的构建方法的影响，我们构建了一个无向图，$\widehat{W}_{ij} = \widehat{W}_{ji} = \max(W_{ij}, W_{ji})$，其中 $\widehat{\boldsymbol{W}}$ 是新的对称权重矩阵。然后我们使用了 DCRNN 的一个变体，表示成 GCRNN，使用 <em>ChebNet</em> 卷积的序列到序列学习，并用大体相同的参数数量。表2展示了 DCRNN 和 GCRNN 在 METR-LA 数据集上的对比。DCRNN 都比 GCRNN 好。这说明有向图能更好的捕获交通检测器之间的非对称关系。图4展示了不同参数的影响。$K$ 大体对应了卷积核感受野的大小，单元数对应了卷积核数。越大的 $K$ 越能使模型捕获更宽的空间依赖，代价是增加了学习的复杂度。我们观测到随着 $K$ 的增加，验证集上的误差先是快速下降，然后微微上升。改变不同数量的单元也会有相似的情况。</p><p><img src="./fig/Table2.JPG" alt="Table2"></p><p><img src="./fig/Fig4.JPG" alt="Fig4"></p><h2 id="4-4-Effect-of-Temporal-Dependency-Modeling"><a href="#4-4-Effect-of-Temporal-Dependency-Modeling" class="headerlink" title="4.4 Effect of Temporal Dependency Modeling"></a>4.4 Effect of Temporal Dependency Modeling</h2><p>为了衡量时间建模的影响，包括序列到序列框架以及 scheduled sampling 技术，我们设计 DCRNN 的三种变体：1. DCNN：我们拼接历史的观测值为一个固定长度的向量，将它放到堆叠的扩散卷积层中，预测未来的时间序列。我们训练一个模型只预测一步，将之前的预测结果放到模型中作为输入，使用多步前向预测。2. DCRNN-SEQ：使用编码解码序列到序列学习框架做多步预测。3. DCRNN：类似 DCRNN-SEQ ，除了增加了 scheduled sampling。</p><p>图5展示了这四种方法针对 MAE 的对比。我们观察到：1. DCRNN-SEQ 比 DCNN 好很多，符合了对时间建模的重要性。2. DCRNN 达到了最好的效果，随着预测 horizon 的增加，它的先进性变得越来越明显。这主要是因为模型在训练的时候就在处理多步预测时出现的误差，因此会很少的受到误差反向传播的影响。我们也训练了一个总是将输出作为输入扔到模型中的模型。但是它的表现比这三种变体都差，这就强调了 scheduled sampling 的重要性。</p><p><img src="./fig/Fig5.JPG" alt="Fig5"></p><h2 id="4-5-模型的解释性"><a href="#4-5-模型的解释性" class="headerlink" title="4.5 模型的解释性"></a>4.5 模型的解释性</h2><p>为了更好的理解模型，我们对预测结果和学习到的滤波器进行性了可视化。图6展示了预测1小时的效果。我们观察到了以下情况：1. DCRNN 在交通流速度中存在小的震荡时，用均值生成了平滑的预测结果（图6a）。这反映了模型的鲁棒性。2. DCRNN 比 baseline 方法（如FC-LSTM）更倾向于精确的预测出突变。图6b展示了 DCRNN 预测了高峰时段的起始和终止。这是因为 DCRNN 捕获了空间依赖，能够利用邻居检测器速度的变换来精确预测。图7展示了以不同顶点为中心学习到的滤波器的样例。星表示中心，颜色表示权重。我们可以观察到权重更好的在中心周围局部化，而且权重基于路网距离进行扩散。更多的可视化在附录F。</p><p><img src="./fig/Fig6.JPG" alt="Fig6"></p><p><img src="./fig/Fig7.JPG" alt="Fig7"></p><h1 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5 Conclusion"></a>5 Conclusion</h1><p>我们对路网上的交通预测做了时空上的建模，提出了 <em>diffusion convolutional recurrent neural network</em>，可以捕获时空依赖。特别地，我们使用双向随机游走，对空间依赖建模，使用循环神经网络捕获时间的动态性。还继承了编码解码架构和 scheduled sampling 技术来提升长期预测的性能。在两个真实的数据集上评估了性能，我们的方法比 baselines 好很多。未来的工作，1. 使用提出的网络解决其他的时空预测问题；2. 对不断演化的图结构的时空依赖关系建模。</p><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="B-Efficient-Calculation-Of-Equation"><a href="#B-Efficient-Calculation-Of-Equation" class="headerlink" title="B Efficient Calculation Of Equation"></a>B Efficient Calculation Of Equation</h2><p>式2可以分解成两个有相同时间复杂度的部分，一部分是 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$，另一部分是 $\boldsymbol{D}^{-1}_I \boldsymbol{W}^T$。因此我们只研究第一部分的时间复杂度。</p><p>令 $T_k(x) = (\boldsymbol{D}^{-1}_O \boldsymbol{W})^k \boldsymbol{x}$，式2的第一部分可以重写为：</p><p>因为 $T_{k+1}(x) = \boldsymbol{D}^{-1}_O \boldsymbol{W} T_k(\boldsymbol{x})$ 和 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$ 是稀疏的，可以很容易看出式4可以通过 $O(K)$ 的递归稀疏-稠密矩阵乘法，每次时间复杂度为 $O(\vert \varepsilon \vert)$ 得到。然后，式2和式4的时间复杂度都为 $O(K\vert \varepsilon \vert)$。对于稠密图，我们可以使用 spectral sparsification(Cheng et al., 2015) 使其稀疏。</p><h2 id="C-Relation-With-Spectral-Graph-Convolution"><a href="#C-Relation-With-Spectral-Graph-Convolution" class="headerlink" title="C Relation With Spectral Graph Convolution"></a>C Relation With Spectral Graph Convolution</h2><p><em>Proof.</em> 谱图卷积利用归一化的拉普拉斯矩阵 $\boldsymbol{L = D^{-\frac{1}{2}}(D - W)D^{\frac{1}{2}}} = \mathbf{\Phi \Lambda \Phi^T}$。ChebNet 使 $f_\theta$ 参数化为一个 $\Lambda$ 的 $K$ 阶多项式，使用稳定的切比雪夫多项式基计算这个值。</p><p>其中 $T_0(x)=1, T_1(x)=x, T_k(x) = xT_{k-1}(x) - T_{k-2}(x)$ 是切比雪夫多项式的基。令 $\lambda_{\mathrm{max}}$ 表示 $\boldsymbol{L}$ 最大的特征值，$\tilde{\boldsymbol{L}} = \frac{2}{\lambda_{\text{max}}} \boldsymbol{L - I}$ 表示将拉普拉斯矩阵的缩放，将特征值从 $[0, \lambda_{\text{max}}]$ 映射到 $[-1, 1]$，因为切比雪夫多项式生成了一个在 $[-1, 1]$ 内正交的基。式5可以看成一个关于 $\tilde{\boldsymbol{L}}$ 的多项式，我们一会儿可以看到，ChebNet 卷积的输出和扩散卷积到常数缩放因子的输出相似。假设 $\lambda_{\text{max}} = 2$，无向图 $\boldsymbol{D}_I = \boldsymbol{D}_O = \boldsymbol{D}$。</p><p>$\tilde{\boldsymbol{L}}$ 和负的随机游走转移矩阵相似，因此式5的输出也和式2直到常数缩放因子的输出相似。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h1&gt;&lt;p&gt;交通预测的挑战：1. 对路网复杂的空间依赖关系， 2. 路况变换与非线性的时间动态性， 3. 长期预测的困难性。我们提出了在有向图上对交通流以扩散形式进行建模的方法，介绍了 &lt;em&gt;Diffusion Convolutional Recurrent Neural Network&lt;/em&gt;(DCRNN)，用于交通预测的深度学习框架，同时集成了交通流中的空间与时间依赖。DCRNN 使用图上的双向随机游走捕获了空间依赖，使用编码解码框架以及 scheduled sampling 捕获时间依赖。我们在两个真实的交通数据集上评估了模型，比 state-of-the-art 强了12%-15%。&lt;/p&gt;
&lt;h1 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h1&gt;</summary>
    
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/categories/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/tags/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    <category term="交通流" scheme="https://leezepeng.github.io/tags/%E4%BA%A4%E9%80%9A%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning 读书笔记 第一章 引言（一）</title>
    <link href="https://leezepeng.github.io/2021/03/13/Deep-Learning-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%BC%95%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://leezepeng.github.io/2021/03/13/Deep-Learning-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%BC%95%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2021-03-13T08:50:01.000Z</published>
    <updated>2021-03-13T08:51:11.876Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_43714954/article/details/88673194?spm=1001.2014.3001.5501">Deep Learning 读书笔记 第一章 引言（一）</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_43714954/article/details/88673194?spm=1001.2014.3001.5501&quot;&gt;Deep Learning 读书笔记 第一章 引言（一）&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://leezepeng.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习初探" scheme="https://leezepeng.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/"/>
    
    <category term="读书笔记" scheme="https://leezepeng.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>CSDN-Deep Learning 读书笔记 第一章 深度学习的历史趋势</title>
    <link href="https://leezepeng.github.io/2021/03/13/CSDN-Deep-Learning-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8E%86%E5%8F%B2%E8%B6%8B%E5%8A%BF/"/>
    <id>https://leezepeng.github.io/2021/03/13/CSDN-Deep-Learning-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8E%86%E5%8F%B2%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-03-13T08:48:30.000Z</published>
    <updated>2021-03-13T08:49:19.710Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_43714954/article/details/88728511?spm=1001.2014.3001.5501">Deep Learning 读书笔记 第一章 深度学习的历史趋势</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_43714954/article/details/88728511?spm=1001.2014.3001.5501&quot;&gt;Deep Learning 读书笔记 第一章 深度学习的历史趋势&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://leezepeng.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习初探" scheme="https://leezepeng.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/"/>
    
    <category term="读书笔记" scheme="https://leezepeng.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>CSDN-门控图神经网络及PyTorch实现</title>
    <link href="https://leezepeng.github.io/2021/03/13/CSDN-%E9%97%A8%E6%8E%A7%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8APyTorch%E5%AE%9E%E7%8E%B0/"/>
    <id>https://leezepeng.github.io/2021/03/13/CSDN-%E9%97%A8%E6%8E%A7%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8APyTorch%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-03-13T08:45:20.000Z</published>
    <updated>2021-03-13T08:47:45.542Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_43714954/article/details/100154348?spm=1001.2014.3001.5501">门控图神经网络及PyTorch实现</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_43714954/article/details/100154348?spm=1001.2014.3001.5501&quot;&gt;门控图神经网络及PyTorch实现&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/categories/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    
    <category term="CSDN" scheme="https://leezepeng.github.io/tags/CSDN/"/>
    
    <category term="论文详解" scheme="https://leezepeng.github.io/tags/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>暑期aifashion项目-Dressing as a Whole: Outfit Compatibility Learning Based on Node-wise Graph Neural Networks</title>
    <link href="https://leezepeng.github.io/2021/03/13/%E6%9A%91%E6%9C%9Faifashion%E9%A1%B9%E7%9B%AE-Dressing-as-a-Whole-Outfit-Compatibility-Learning-Based-on-Node-wise-Graph-Neural-Networks/"/>
    <id>https://leezepeng.github.io/2021/03/13/%E6%9A%91%E6%9C%9Faifashion%E9%A1%B9%E7%9B%AE-Dressing-as-a-Whole-Outfit-Compatibility-Learning-Based-on-Node-wise-Graph-Neural-Networks/</id>
    <published>2021-03-13T07:20:30.000Z</published>
    <updated>2021-03-13T08:46:40.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="国内外研究的不足："><a href="#国内外研究的不足：" class="headerlink" title="国内外研究的不足："></a>国内外研究的不足：</h2><h3 id="对兼容性的评估方法的不足："><a href="#对兼容性的评估方法的不足：" class="headerlink" title="对兼容性的评估方法的不足："></a>对兼容性的评估方法的不足：</h3><ul><li>McAuley等人使用低秩马氏变换(LMT)将单品映射到一个潜在空间，在这个空间中，可兼容的物品距离更近。    </li><li>Veit等人提出使用端到端SiameseCNNs学习距离度量。</li><li>还有一些研究将单品映射到多个潜在空间中，共同对这些潜在空间中的距离进行建模，从而可以衡量物品在不同方面的相容性。</li></ul><p>这些方法都有一个共同的缺陷，<strong>这些工作只注重两两单品的搭配，而不是整体的搭配。</strong></p><h3 id="对单品间关系表达的不足："><a href="#对单品间关系表达的不足：" class="headerlink" title="对单品间关系表达的不足："></a>对单品间关系表达的不足：</h3><span id="more"></span><ul><li>Li等人从项目中提取多模态信息，并用循环神经网络(RNN)[17]评估装备的兼容性。</li><li>Han等人将一套服装表现为具有特定顺序的序列。然后使用双向LSTMs来预测下一件物品，同时也预测了套装的兼容性分数。</li></ul><p>这些方法也有个共同缺陷，<strong>单品的顺序不存在固定的。更重要的是，服装中物品之间的关系并不是有序的，因为物品在序列中不仅与其前面的单品有关系与后面的单品也有关系。</strong></p><h3 id="对图结构数据处理方式的不足："><a href="#对图结构数据处理方式的不足：" class="headerlink" title="对图结构数据处理方式的不足："></a>对图结构数据处理方式的不足：</h3><h4 id="节点间的信息传递问题："><a href="#节点间的信息传递问题：" class="headerlink" title="节点间的信息传递问题："></a>节点间的信息传递问题：</h4><p>Gori等人首先提出了图神经网络(GNN)，将前馈神经网络递归应用于图中的每个节点。节点通过传递它们的状态信息与其他节点进行交互。Scarselli等人利用多层感知(MLP)更新节点的隐藏状态。然而，在图中<strong>信息的远距离传播存在问题</strong>。</p><h4 id="图数据大且复杂导致的问题："><a href="#图数据大且复杂导致的问题：" class="headerlink" title="图数据大且复杂导致的问题："></a>图数据大且复杂导致的问题：</h4><p>为解决节点间信息的远距离传播导致信息消亡的问题，Li等人通过引入门控递归单元(GRU)来更新节点，提出了门控图神经网络(GGNN)。然而，该算法<strong>仅适用于无向图，不能模拟两节点有向边之间复杂而灵活的信息传递。</strong></p><h2 id="本文的贡献"><a href="#本文的贡献" class="headerlink" title="本文的贡献"></a>本文的贡献</h2><p><strong>为解决上述问题，作者提出了一个新的模型**</strong>NGNN<strong>**，它可以更好地模拟节点的交互，从而更好地从图中推断套装的兼容性。在NGNN中，每条边的状态信息传递是不同的。它可以用节点的参数来建模沿边的信息传递。</strong></p><ul><li>据我们所知，这是第一次尝试用本文的图结构来表示套装，它可以更好地捕捉服装中多个元素之间的复杂关系。</li><li>我们提出了一个新的模型NGNN，它可以更好地模拟图中的节点交互，并学习更好的节点表示。利用NGNN，我们不仅可以从<strong>视觉或文本</strong>的模态，而且可以从多种模态建模服装的兼容性。</li><li>在一个真实数据集(Polyvore数据集)上的实验结果证明了我们的方法比其他方法的巨大优越性。</li></ul><h2 id="流程总览"><a href="#流程总览" class="headerlink" title="流程总览"></a>流程总览</h2><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597039788378-f0078c12-9f4f-4e65-9fc6-c8e23e0a2939.png?x-oss-process=image%2Fresize%2Cw_1028" alt="image.png"><br>图1：NGNN模型总览<br>首先将单品（衣服、裤子、鞋子、包）的<strong>图片及其文本描述</strong>（Polyvore数据集中有对单品材质颜色等描述）输入表示层，得到每件单品的特征向量，将特征向量与我们的图（每个节点代表一个类别，每条边代表两个节点之间的交互。一套服装(如毛衣、短衫、凉鞋、肩包)可以用子图表示。）对应起来作为节点的特征向量并提取子图，利用改进的GGNN的传播方法进行节点间信息的传播，将传播后的特征向量通过注意力层计算相容性评分。</p><h2 id="图的构建"><a href="#图的构建" class="headerlink" title="图的构建"></a>图的构建</h2><ul><li>节点：单品类别，如太阳镜，短裤，项链。</li><li>节点对应特征向量：<ol><li>视觉特性：利用高级深度卷积神经网络GoogleNet InceptionV3模型提取视觉特征，并采用线性层输出作为视觉特征。每个项目的视觉特征是一个2048维的向量。</li><li>文本特性：首先根据数据集中标题的单词构造一个词汇表。因为有很多无意义的单词，比如“a”、“an”和“de”，我们会过滤掉少于3个字符的单词。最后，我们获得了一个包含2757个单词的词汇表，因此我们将每个条目的文本特征表示为一个2757维布尔向量。</li></ol></li><li>边：如果两种单品类别在数据集中同时出现，则添加两条有向边，因为两个方向上的交互作用应该是不同的。比如我们不会为了匹配一双袜子而买鞋子，而是为了匹配一双鞋子而买袜子。</li><li>边的权重计算：利用词频的方法：</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597041336396-d9edb972-43ea-4446-be4d-8e49eb75e0e1.png" alt="image.png" style="zoom:70%;" />(1)<br>其中w(ni,nj)为ni到nj的边权值，Countcicj 为类别ci和cj共现频率是多少，Countcj 为类别cj的出现频率。</p><h2 id="Node-wise-Graph-Neural-Network"><a href="#Node-wise-Graph-Neural-Network" class="headerlink" title="Node-wise Graph Neural Network"></a>Node-wise Graph Neural Network</h2><h3 id="节点的初始化"><a href="#节点的初始化" class="headerlink" title="节点的初始化"></a>节点的初始化</h3><p>在NGNN中，每个节点ni都与一个隐藏状态向量hi相关联，并动态更新。NGNN的输入是单品的特征向量(图片或文本的特征向量)，可用于初始化对应节点的状态。对于每一单品vi，我们首先将其特征fi映射到一个大小为d的潜在风格空间。考虑到类别之间的差异，我们对每个类别ci都有一个线性映射矩阵Wih。因此，我们可以得到单品vi在潜在空间中的表示为:<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597042454519-cae580b3-bf84-442a-b563-29fd7cd4a43b.png?x-oss-process=image%2Fresize%2Cw_94" alt="image.png" style="zoom:67%;" /><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597042590414-972c82f3-d1fc-4f85-8241-f868958bcf4b.png?x-oss-process=image%2Fresize%2Cw_124" alt="image.png" style="zoom:67%;" /></p><p>因此，节点状态的大小为d。</p><h3 id="节点间信息传播"><a href="#节点间信息传播" class="headerlink" title="节点间信息传播"></a>节点间信息传播</h3><p>GGNN与本模型的比较：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597043017623-6d1f1aa1-ce45-4254-ad5b-b5d3fb696a69.png" alt="image.png"><br>即让每条边都有自己的权值和偏差Wp和bp。但是，它会占用图中大量边的参数空间，不能应用在大尺度图上。为了解决上述问题，对于NGNN中的每个节点ni，我们定义输出矩阵Wouti和一个输入矩阵Wini。<br>同样的，在接收到状态信息ait后，节点ni的状态将更新为:<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597044053826-80e2fc73-aa1b-448b-a8ff-a6483a39ac2c.png" alt="image.png"><br>其中，Wz、Wr、Wh、bz、br、bh为更新函数的权值和偏值。经过T个传播步骤，我们可以得到节点的最终状态，这也是节点的最终表示。</p><h3 id="基于注意机制的兼容性计算"><a href="#基于注意机制的兼容性计算" class="headerlink" title="基于注意机制的兼容性计算"></a>基于注意机制的兼容性计算</h3><div  align="center"><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597044189735-18d5a6a7-32b8-4678-afc8-57740688c62f.png?x-oss-process=image%2Fresize%2Cw_230" alt="image.png" style="zoom:67%;" /></div><p>θ(·) 和 δ(·)分别是两个重要性网络，前者学出每个单品的权重，后者学出单品的评分。α(·) 和σ(·) 是 leaky relu 和 sigmoid函数。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>本文将数据集中同时出现的单品作为正样本的集合 S+，把单品的随机组合作为负样本的集合 S- 。损失函数如下：</p><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597044826770-377b8f82-bdc4-4f9b-81e6-8e925d8600f9.png" width = 30%/> </div><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597044851756-51d9a66f-d276-48ec-b3bc-56cbc7ca6084.png" width = 30%/> </div><p>对于既输入图片特征，又输入文本特征的情况：</p><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597044984089-fd19368a-075c-4355-9fc1-ea85b0689c83.png" width = 30%/> </div><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597045007719-c7a16b2d-cea2-4428-9853-5b0f423083c0.png?x-oss-process=image%2Fresize%2Cw_244" width = 30%/> </div><p>r已经在上文中定义。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597045096603-7048b13e-b6a8-4f90-a2ee-48985596bd74.png" width = 60%/> </div><div align=center> <img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597045122733-fa10bf83-9261-4ee0-bf6c-fb0a606a9bd1.png" width = 30%/><img src="https://cdn.nlark.com/yuque/0/2020/png/1842325/1597045132882-289c08fa-7e5e-4263-a4c9-172323923dbe.png" width = 30%/> </div>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;国内外研究的不足：&quot;&gt;&lt;a href=&quot;#国内外研究的不足：&quot; class=&quot;headerlink&quot; title=&quot;国内外研究的不足：&quot;&gt;&lt;/a&gt;国内外研究的不足：&lt;/h2&gt;&lt;h3 id=&quot;对兼容性的评估方法的不足：&quot;&gt;&lt;a href=&quot;#对兼容性的评估方法的不足：&quot; class=&quot;headerlink&quot; title=&quot;对兼容性的评估方法的不足：&quot;&gt;&lt;/a&gt;对兼容性的评估方法的不足：&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;McAuley等人使用低秩马氏变换(LMT)将单品映射到一个潜在空间，在这个空间中，可兼容的物品距离更近。    &lt;/li&gt;
&lt;li&gt;Veit等人提出使用端到端SiameseCNNs学习距离度量。&lt;/li&gt;
&lt;li&gt;还有一些研究将单品映射到多个潜在空间中，共同对这些潜在空间中的距离进行建模，从而可以衡量物品在不同方面的相容性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些方法都有一个共同的缺陷，&lt;strong&gt;这些工作只注重两两单品的搭配，而不是整体的搭配。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;对单品间关系表达的不足：&quot;&gt;&lt;a href=&quot;#对单品间关系表达的不足：&quot; class=&quot;headerlink&quot; title=&quot;对单品间关系表达的不足：&quot;&gt;&lt;/a&gt;对单品间关系表达的不足：&lt;/h3&gt;</summary>
    
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/categories/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    
    <category term="论文详解" scheme="https://leezepeng.github.io/tags/%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    
    <category term="aifashion" scheme="https://leezepeng.github.io/tags/aifashion/"/>
    
  </entry>
  
  <entry>
    <title>暑期aifashion项目-模型总体流程</title>
    <link href="https://leezepeng.github.io/2021/03/13/%E6%9A%91%E6%9C%9Faifashion%E9%A1%B9%E7%9B%AE-%E6%A8%A1%E5%9E%8B%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B/"/>
    <id>https://leezepeng.github.io/2021/03/13/%E6%9A%91%E6%9C%9Faifashion%E9%A1%B9%E7%9B%AE-%E6%A8%A1%E5%9E%8B%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B/</id>
    <published>2021-03-13T07:04:48.000Z</published>
    <updated>2021-03-13T07:14:46.112Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://imgtu.com/i/6d2u7D"><img src="https://s3.ax1x.com/2021/03/13/6d2u7D.png" alt="6d2u7D.png"></a></p><p>首先将人工标注与Polyvore数据集的知识融合获得知识图谱，与此同时利用残差神经网络分别提取人的上衣，下衣（或全身），脸形，体型对应的具体属性（如印花，方型脸）对应的特征向量，将具体属性在知识图谱中实例化（彩色即为实例化后的节点）并与知识图谱的特征向量拼接，获得第三层（黄色：具体特征层）所有节点结合了知识图谱语义信息和残差神经网络的图像信息的特征向量。对第三层利用GGNN模型进行信息传播与更新，更新T轮后利用Diff-Pooling的方法将第三层节点信息映射至第二层节点（橙色：单品层），最后将单品层所有节点的特征向量拼接，通过全连接神经网络计算出第一层（灰色：套装层）的Compability评分。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://imgtu.com/i/6d2u7D&quot;&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/03/13/6d2u7D.png&quot; alt=&quot;6d2u7D.png&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;首先将人工标注与Polyvore数据</summary>
      
    
    
    
    <category term="aifasion" scheme="https://leezepeng.github.io/categories/aifasion/"/>
    
    
    <category term="aifashion" scheme="https://leezepeng.github.io/tags/aifashion/"/>
    
    <category term="模型流程" scheme="https://leezepeng.github.io/tags/%E6%A8%A1%E5%9E%8B%E6%B5%81%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>新的开始</title>
    <link href="https://leezepeng.github.io/2021/03/13/hello-world/"/>
    <id>https://leezepeng.github.io/2021/03/13/hello-world/</id>
    <published>2021-03-13T02:57:00.000Z</published>
    <updated>2021-03-13T03:04:41.838Z</updated>
    
    <content type="html"><![CDATA[<p>今天是博客诞生的第一天，先前的一些CSDN上，语雀上的博客会被整合进这里，从大一开始做了2年多的深度学习，很感谢指导我的老师以及师兄师姐们，在大三面临着读研还是工作的十字路口，我还是决定从现在开始记录我的java学习过程来应对秋招和夏令营，中间会穿插一些模型压缩的论文解析（每周论文汇报不能少），废话不多说，现在开始！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天是博客诞生的第一天，先前的一些CSDN上，语雀上的博客会被整合进这里，从大一开始做了2年多的深度学习，很感谢指导我的老师以及师兄师姐们，在大三面临着读研还是工作的十字路口，我还是决定从现在开始记录我的java学习过程来应对秋招和夏令营，中间会穿插一些模型压缩的论文解析（</summary>
      
    
    
    
    <category term="杂谈" scheme="https://leezepeng.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="杂谈" scheme="https://leezepeng.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
    <category term="第一篇博客" scheme="https://leezepeng.github.io/tags/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
</feed>
